{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061930ec-9660-4dae-aeb6-5c46325f6cc0",
   "metadata": {
    "id": "061930ec-9660-4dae-aeb6-5c46325f6cc0"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b18d4-0a15-400c-b9d6-36ad12925233",
   "metadata": {
    "id": "144b18d4-0a15-400c-b9d6-36ad12925233"
   },
   "source": [
    "## 파이썬으로 간단하게 구현한 퍼셉트론-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3226bdd1-30e7-498f-9846-bba187b8038a",
   "metadata": {
    "id": "3226bdd1-30e7-498f-9846-bba187b8038a",
    "outputId": "7fafbefb-4d30-447a-c6e4-c382e361c960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([1,0,1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac59493-900c-443d-8f86-320faf21702f",
   "metadata": {
    "id": "9ac59493-900c-443d-8f86-320faf21702f",
    "outputId": "f43b992d-8ae1-4408-bce7-f01d9781348f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  1. ,  1. ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W=np.array([\n",
    "    -0.5,\n",
    "    1.0,\n",
    "    1.0\n",
    "])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9855f20-085d-453e-bfbe-5c9c916bbc9a",
   "metadata": {
    "id": "e9855f20-085d-453e-bfbe-5c9c916bbc9a",
    "outputId": "bc28ceec-788c-4017-aa4d-06cab2de37be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=sum(X*W)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952b2e9-d5bd-4854-a75b-e895f78a044f",
   "metadata": {
    "id": "0952b2e9-d5bd-4854-a75b-e895f78a044f"
   },
   "source": [
    "## 파이썬으로 간단하게 구현한 퍼셉트론-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74503d9a-c713-429a-83ab-e3b5aa8fbab0",
   "metadata": {
    "id": "74503d9a-c713-429a-83ab-e3b5aa8fbab0",
    "outputId": "d7ca078e-e13c-4684-acff-8f6e856497b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([\n",
    "            [1,0,0],\n",
    "            [1,0,1],\n",
    "            [1,1,0],\n",
    "            [1,1,1]\n",
    "])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c70aa1-0e76-4b06-85e6-5e3967c894dc",
   "metadata": {
    "id": "b0c70aa1-0e76-4b06-85e6-5e3967c894dc",
    "outputId": "cdcee897-aaf7-49ff-e75e-b8f0fbbf0215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  1. ,  1. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W=np.array([\n",
    "    -0.5,\n",
    "    1.0,\n",
    "    1.0\n",
    "])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f67dc5-f8b6-4619-aac6-4b274b5fe367",
   "metadata": {
    "id": "37f67dc5-f8b6-4619-aac6-4b274b5fe367",
    "outputId": "398066d8-6cf6-4663-f34c-9fb8fad60754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  0.5,  0.5,  1.5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.sum(X*W, axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e2471-1409-43e2-b88d-4576bea0e7ef",
   "metadata": {
    "id": "8d5e2471-1409-43e2-b88d-4576bea0e7ef"
   },
   "source": [
    "## SLP를 통한 AND, OR, NOT 게이트 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c4b58-fe21-4fca-a559-0223c4904644",
   "metadata": {
    "id": "154c4b58-fe21-4fca-a559-0223c4904644"
   },
   "source": [
    "### 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3cbc30-c961-4f84-a699-abd3e0389723",
   "metadata": {
    "id": "3f3cbc30-c961-4f84-a699-abd3e0389723",
    "outputId": "597ddbe5-7525-4616-c15e-23285f680de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ AND Perceptron +++\n",
      "[0 0] >>> 0\n",
      "[0 1] >>> 0\n",
      "[1 0] >>> 0\n",
      "[1 1] >>> 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def ANDperceptron(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.7\n",
    "    tmp = x1*w1 + x2*w2\n",
    "    if tmp <= theta:\n",
    "        return 0\n",
    "    elif tmp > theta:\n",
    "        return 1\n",
    "\n",
    "inputData = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "print(\"+++ AND Perceptron +++\")\n",
    "for xs in inputData:\n",
    "    print(str(xs) + \" >>> \" + str(ANDperceptron(xs[0], xs[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce972a2-7a72-4d88-8825-63abe05b4afd",
   "metadata": {
    "id": "5ce972a2-7a72-4d88-8825-63abe05b4afd",
    "outputId": "df71ef0c-4833-4aa2-90c9-e7cca6e52d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ AND Perceptron +++\n",
      "[0 0] >>> 0\n",
      "[0 1] >>> 0\n",
      "[1 0] >>> 0\n",
      "[1 1] >>> 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def ANDperceptron(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    elif tmp > 0:\n",
    "        return 1\n",
    "\n",
    "inputData = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "print(\"+++ AND Perceptron +++\")\n",
    "\n",
    "for xs in inputData:\n",
    "    print(str(xs) + \" >>> \" + str(ANDperceptron(xs[0], xs[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0cfad6e-f5cc-4ced-af45-372808e91379",
   "metadata": {
    "id": "b0cfad6e-f5cc-4ced-af45-372808e91379",
    "outputId": "4ba999e3-a34f-4c46-d0f2-c76ea62cbd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [2.14037745 1.2763927 ]\n",
      "b: -9\n",
      "\n",
      "Test:\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#데이터 생성\n",
    "rng = np.random.RandomState(123)\n",
    "d = 2\n",
    "N = 10\n",
    "mean = 5\n",
    "x1 = rng.randn(N, d) + np.array([0, 0])\n",
    "x2 = rng.randn(N, d) + np.array([mean, mean])\n",
    "x = np.concatenate((x1, x2), axis=0)\n",
    "\n",
    "#단순 퍼셉트론\n",
    "w = np.zeros(d)\n",
    "b = 0\n",
    "\n",
    "def y(x):\n",
    "    return step(np.dot(w, x) + b)\n",
    "\n",
    "def step(x):\n",
    "    return 1 * (x > 0)\n",
    "\n",
    "def t(i):\n",
    "    if i < N:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "while True:\n",
    "    classified = True\n",
    "    for i in range(N * 2):\n",
    "        delta_w = (t(i) - y(x[i])) * x[i]\n",
    "        delta_b = (t(i) - y(x[i]))\n",
    "        w += delta_w\n",
    "        b += delta_b\n",
    "        classified *= all(delta_w == 0) * (delta_b == 0)\n",
    "    if classified:\n",
    "        break\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('\\nTest:')\n",
    "print(y([0, 0]))  # => 0\n",
    "print(y([5, 5]))  # => 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bd6ff-59da-4c86-b749-b576deff8876",
   "metadata": {
    "id": "cf3bd6ff-59da-4c86-b749-b576deff8876"
   },
   "source": [
    "### AND 게이트 단순 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40d0d43-e891-4445-9bd8-2049ac2fb945",
   "metadata": {
    "id": "f40d0d43-e891-4445-9bd8-2049ac2fb945",
    "outputId": "a4fe8de6-18d2-4629-ea26-6c3a20e678ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "0번째 반복 입니다\n",
      "0.01\n",
      "1번째 반복 입니다\n",
      "0.01\n",
      "2번째 반복 입니다\n",
      "-0.02\n",
      "3번째 반복 입니다\n",
      "0.01\n",
      "4번째 반복 입니다\n",
      "0.0\n",
      "[0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# AND 데이터 만들기\n",
    "\n",
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# 1단계 : 가중치 초기화\n",
    "\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "\n",
    "# 최초 분류\n",
    "\n",
    "input_signal = np.dot(X, w[1:]) + w[0]\n",
    "def out_put(X):\n",
    "    return np.where(X >= 0.0, 1, 0)\n",
    "pred_y = out_put(input_signal)\n",
    "print(pred_y)\n",
    "\n",
    "# 가중치 최적화 시작\n",
    "\n",
    "errors = []\n",
    "epoch = 100\n",
    "for time in range(0, epoch):\n",
    "    print(\"{0}번째 반복 입니다\".format(time))\n",
    "    eta = 0.01\n",
    "    idx = 0\n",
    "    for xi, target in zip(X, y):\n",
    "        updated_w = eta * (target - pred_y[idx])\n",
    "        w[1:] += updated_w * xi\n",
    "        w[0] += updated_w\n",
    "        idx += 1\n",
    "    input_signal = np.dot(X, w[1:]) + w[0]\n",
    "    pred_y = out_put(input_signal)\n",
    "    errors.append(((y - pred_y).sum()) / 100)\n",
    "    print(((y - pred_y).sum()) / 100)\n",
    "    if ((y - pred_y).sum()) / 100 == 0:\n",
    "        break\n",
    "\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8d8cb-4c8a-4f60-9b06-e9dcf0984650",
   "metadata": {
    "id": "5cf8d8cb-4c8a-4f60-9b06-e9dcf0984650"
   },
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2c1f9e-f29b-4cab-8a9d-681523c40eb6",
   "metadata": {
    "id": "0d2c1f9e-f29b-4cab-8a9d-681523c40eb6",
    "outputId": "577e382c-33dc-4ce3-bc50-fb59c6879a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "0번째 반복 입니다\n",
      "0.03\n",
      "1번째 반복 입니다\n",
      "-0.01\n",
      "2번째 반복 입니다\n",
      "-0.01\n",
      "3번째 반복 입니다\n",
      "-0.01\n",
      "4번째 반복 입니다\n",
      "0.0\n",
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# OR 데이터 만들기\n",
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "# 1단계 : 가중치 초기화\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "\n",
    "# 최초 분류\n",
    "input_signal = np.dot(X, w[1:]) + w[0]\n",
    "\n",
    "def out_put(X):\n",
    "    return np.where(X >= 0.0, 1, 0)\n",
    "\n",
    "pred_y = out_put(input_signal)\n",
    "print(pred_y)\n",
    "\n",
    "# 가중치 최적화 시작\n",
    "errors = []\n",
    "epoch = 100\n",
    "for time in range(0, epoch):\n",
    "    print(\"{0}번째 반복 입니다\".format(time))\n",
    "    eta = 0.01\n",
    "    idx = 0\n",
    "    for xi, target in zip(X, y):\n",
    "        updated_w = eta * (target - pred_y[idx])\n",
    "        w[1:] += updated_w * xi\n",
    "        w[0] += updated_w\n",
    "        idx += 1\n",
    "    input_signal = np.dot(X, w[1:]) + w[0]\n",
    "    pred_y = out_put(input_signal)\n",
    "    errors.append(((y - pred_y).sum()) / 100)\n",
    "    print(((y - pred_y).sum()) / 100)\n",
    "    if ((y - pred_y).sum()) / 100 == 0:\n",
    "        break\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db55e34-b689-472c-9783-59bfe852bd8b",
   "metadata": {
    "id": "9db55e34-b689-472c-9783-59bfe852bd8b"
   },
   "source": [
    "### NAND 게이트 단순 퍼셉트론 화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8551fe99-bf7d-4f94-8ff5-9a3d27fa8bc4",
   "metadata": {
    "id": "8551fe99-bf7d-4f94-8ff5-9a3d27fa8bc4",
    "outputId": "5ab74014-d1e5-4fc9-a429-0589f92efbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "0번째 반복 입니다\n",
      "0.01\n",
      "1번째 반복 입니다\n",
      "0.01\n",
      "2번째 반복 입니다\n",
      "0.01\n",
      "3번째 반복 입니다\n",
      "0.0\n",
      "[1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NAND 데이터 만들기\n",
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([1, 0, 0, 0])\n",
    "\n",
    "# 1단계 : 가중치 초기화\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "\n",
    "# 최초 분류\n",
    "input_signal = np.dot(X, w[1:]) + w[0]\n",
    "\n",
    "def out_put(X):\n",
    "    return np.where(X >= 0.0, 1, 0)\n",
    "\n",
    "pred_y = out_put(input_signal)\n",
    "print(pred_y)\n",
    "\n",
    "# 가중치 최적화 시작\n",
    "errors = []\n",
    "epoch = 100\n",
    "for time in range(0, epoch):\n",
    "    print(\"{0}번째 반복 입니다\".format(time))\n",
    "    eta = 0.01\n",
    "    idx = 0\n",
    "    for xi, target in zip(X, y):\n",
    "        updated_w = eta * (target - pred_y[idx])\n",
    "        w[1:] += updated_w * xi\n",
    "        w[0] += updated_w\n",
    "        idx += 1\n",
    "    input_signal = np.dot(X, w[1:]) + w[0]\n",
    "    pred_y = out_put(input_signal)\n",
    "    errors.append(((y - pred_y).sum()) / 100)\n",
    "    print(((y - pred_y).sum()) / 100)\n",
    "    if ((y - pred_y).sum()) / 100 == 0:\n",
    "        break\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea87508-2202-4471-81c7-3a7ea9884546",
   "metadata": {
    "id": "3ea87508-2202-4471-81c7-3a7ea9884546"
   },
   "source": [
    "### Quiz- NOR  게이트 단순 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f999c31-2ae5-43a9-a3a7-c8fc1febd948",
   "metadata": {
    "id": "5f999c31-2ae5-43a9-a3a7-c8fc1febd948",
    "outputId": "c5ffe5fc-f0d4-4f06-e742-018cf4b28ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "0번째 반복 입니다\n",
      "0.03\n",
      "1번째 반복 입니다\n",
      "-0.01\n",
      "2번째 반복 입니다\n",
      "0.0\n",
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Quiz- NOR 데이터 만들기\n",
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.array([1, 1, 1, 0])\n",
    "\n",
    "# 1단계 : 가중치 초기화\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "\n",
    "# 최초 분류\n",
    "input_signal = np.dot(X, w[1:]) + w[0]\n",
    "\n",
    "def out_put(X):\n",
    "    return np.where(X >= 0.0, 1, 0)\n",
    "\n",
    "pred_y = out_put(input_signal)\n",
    "print(pred_y)\n",
    "\n",
    "# 가중치 최적화 시작\n",
    "errors = []\n",
    "epoch = 100\n",
    "for time in range(0, epoch):\n",
    "    print(\"{0}번째 반복 입니다\".format(time))\n",
    "    eta = 0.01\n",
    "    idx = 0\n",
    "    for xi, target in zip(X, y):\n",
    "        updated_w = eta * (target - pred_y[idx])\n",
    "        w[1:] += updated_w * xi\n",
    "        w[0] += updated_w\n",
    "        idx += 1\n",
    "    input_signal = np.dot(X, w[1:]) + w[0]\n",
    "    pred_y = out_put(input_signal)\n",
    "    errors.append(((y - pred_y).sum()) / 100)\n",
    "    print(((y - pred_y).sum()) / 100)\n",
    "    if ((y - pred_y).sum()) / 100 == 0:\n",
    "        break\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35311f7-358e-45ba-bd0e-c862ac41f7b6",
   "metadata": {
    "id": "f35311f7-358e-45ba-bd0e-c862ac41f7b6"
   },
   "source": [
    "### XOR 게이트 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea36ed5c-b317-46fd-bc6d-7e56c8fd477e",
   "metadata": {
    "id": "ea36ed5c-b317-46fd-bc6d-7e56c8fd477e"
   },
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    elif tmp > 0:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])\n",
    "    b = 0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5417224-5d89-44db-8dfe-1cfea057b957",
   "metadata": {
    "id": "a5417224-5d89-44db-8dfe-1cfea057b957",
    "outputId": "ac473bac-b6d9-44ce-94d2-aa62f8b1bbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(XOR(0,0))\n",
    "print(XOR(1,0))\n",
    "print(XOR(0,1))\n",
    "print(XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb208bf3-f029-4b71-be7d-487cab5bb408",
   "metadata": {
    "id": "eb208bf3-f029-4b71-be7d-487cab5bb408"
   },
   "source": [
    "# XOR 문제를 MLP로 풀어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f91e4-53c5-4879-a1c2-c4a479ec347e",
   "metadata": {
    "id": "f10f91e4-53c5-4879-a1c2-c4a479ec347e"
   },
   "source": [
    "## 파이썬 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b5b3cb-ef9b-4f36-a077-0b1bc35ca742",
   "metadata": {
    "id": "d2b5b3cb-ef9b-4f36-a077-0b1bc35ca742",
    "outputId": "e2df575f-c79c-489d-c6b6-c2942b53cf27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 에러 값 =  4.127670390247806\n",
      "step =  0 에러 값 =  4.07978526058836\n",
      "step =  400 에러 값 =  1.5621020980112343\n",
      "step =  800 에러 값 =  1.1555769156034355\n",
      "step =  1200 에러 값 =  0.9268398356910397\n",
      "step =  1600 에러 값 =  0.7765611656753602\n",
      "step =  2000 에러 값 =  0.6688617148800461\n",
      "step =  2400 에러 값 =  0.5873652861290213\n",
      "step =  2800 에러 값 =  0.5233542153139319\n",
      "step =  3200 에러 값 =  0.47168027911926336\n",
      "step =  3600 에러 값 =  0.4290725157635775\n",
      "step =  4000 에러 값 =  0.3933378034154106\n",
      "step =  4400 에러 값 =  0.3629439114779699\n",
      "step =  4800 에러 값 =  0.33678492977990254\n",
      "step =  5200 에러 값 =  0.3140412439127129\n",
      "step =  5600 에러 값 =  0.2940918916722082\n",
      "step =  6000 에러 값 =  0.276457542357491\n",
      "step =  6400 에러 값 =  0.2607621873207216\n",
      "step =  6800 에러 값 =  0.24670669298371944\n",
      "step =  7200 에러 값 =  0.23405011288992456\n",
      "step =  7600 에러 값 =  0.2225962125932231\n",
      "step =  8000 에러 값 =  0.21218357914171548\n",
      "AND_GATE \n",
      "\n",
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 0 \n",
      "\n",
      "[1 0] = 0 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n",
      "초기 에러 값 =  2.879969188781502\n",
      "step =  0 에러 값 =  2.8709525860134146\n",
      "step =  400 에러 값 =  1.5991548220908902\n",
      "step =  800 에러 값 =  1.1723012484718203\n",
      "step =  1200 에러 값 =  0.9367443825478081\n",
      "step =  1600 에러 값 =  0.7833068617640244\n",
      "step =  2000 에러 값 =  0.6738214463948826\n",
      "step =  2400 에러 값 =  0.5911889522857944\n",
      "step =  2800 에러 값 =  0.5263999461200449\n",
      "step =  3200 에러 값 =  0.47416600077272253\n",
      "step =  3600 에러 값 =  0.431140154639719\n",
      "step =  4000 에러 값 =  0.39508444954766475\n",
      "step =  4400 에러 값 =  0.3644385172569986\n",
      "step =  4800 에러 값 =  0.33807793953468657\n",
      "step =  5200 에러 값 =  0.3151704680652941\n",
      "step =  5600 에러 값 =  0.29508625265592353\n",
      "step =  6000 에러 값 =  0.2773395509574961\n",
      "step =  6400 에러 값 =  0.26154962941389626\n",
      "step =  6800 에러 값 =  0.24741380789787326\n",
      "step =  7200 에러 값 =  0.23468843472460657\n",
      "step =  7600 에러 값 =  0.2231751824110259\n",
      "step =  8000 에러 값 =  0.2127109979477353\n",
      "NAND_GATE \n",
      "\n",
      "[0 0] = 1 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 0 \n",
      "\n",
      "초기 에러 값 =  1.757872661324702\n",
      "step =  0 에러 값 =  1.750556137520679\n",
      "step =  400 에러 값 =  1.0157768155564884\n",
      "step =  800 에러 값 =  0.7509155933878006\n",
      "step =  1200 에러 값 =  0.5907764441303314\n",
      "step =  1600 에러 값 =  0.4843464889108099\n",
      "step =  2000 에러 값 =  0.4089178868803867\n",
      "step =  2400 에러 값 =  0.35291406398529074\n",
      "step =  2800 에러 값 =  0.30983287465937664\n",
      "step =  3200 에러 값 =  0.2757523089860518\n",
      "step =  3600 에러 값 =  0.2481734753061434\n",
      "step =  4000 에러 값 =  0.225433194116311\n",
      "step =  4400 에러 값 =  0.20638420916740724\n",
      "step =  4800 에러 값 =  0.19021110684998407\n",
      "step =  5200 에러 값 =  0.17631938769213773\n",
      "step =  5600 에러 값 =  0.16426599942986353\n",
      "step =  6000 에러 값 =  0.15371438193959408\n",
      "step =  6400 에러 값 =  0.14440453537183953\n",
      "step =  6800 에러 값 =  0.13613258826798819\n",
      "step =  7200 에러 값 =  0.1287365399719114\n",
      "step =  7600 에러 값 =  0.12208611444505142\n",
      "step =  8000 에러 값 =  0.1160754117479978\n",
      "OR_GATE \n",
      "\n",
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n",
      "[0 0] = 0\n",
      "\n",
      "[0 1] = 1\n",
      "\n",
      "[1 0] = 1\n",
      "\n",
      "[1 1] = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 패키지 로드\n",
    "import numpy as np\n",
    "\n",
    "# 2. MLP 구조 구성하는 게이트 클래스 구현\n",
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "def numerical_derivative(f, x):\n",
    "  delta_x = 1e-4\n",
    "  grad = np.zeros_like(x)\n",
    "  it=np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "  while not it.finished:\n",
    "    idx=it.multi_index\n",
    "    tmp_val=x[idx]\n",
    "    x[idx]=float(tmp_val) + delta_x\n",
    "    fx1 = f(x)\n",
    "    x[idx]=float(tmp_val) - delta_x\n",
    "    fx2 = f(x)\n",
    "    grad[idx]=(fx1 - fx2) / (2*delta_x)\n",
    "    x[idx]=tmp_val\n",
    "    it.iternext()\n",
    "  return grad\n",
    "\n",
    "\n",
    "class LogicGate:\n",
    "  def __init__(self, gate_name, xdata, tdata):\n",
    "    self.name=gate_name\n",
    "    self.__xdata=xdata.reshape(4,2)\n",
    "    self.__tdata=tdata.reshape(4,1)\n",
    "    self.__w=np.random.rand(2,1)\n",
    "    self.__b=np.random.rand(1)\n",
    "    self.__learning_rate=1e-2\n",
    "  # 손실 함수\n",
    "  def __loss_function(self):\n",
    "    delta=1e-7\n",
    "    z=np.dot(self.__xdata, self.__w) + self.__b\n",
    "    y=sigmoid(z)\n",
    "    return -np.sum(self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta))\n",
    "  # 손실 값 계산 함수\n",
    "  def error_val(self):\n",
    "    return self.__loss_function()\n",
    "\n",
    "\n",
    "#학습\n",
    "  def train(self):\n",
    "    #손실함수 계산\n",
    "    f=lambda x: self.__loss_function()\n",
    "    print(\"초기 에러 값 = \", self.error_val())\n",
    "    #손실함수에 대해 경사하강 가중치, 바이어스 업데이트\n",
    "    for step in range(8001):\n",
    "      self.__w -= self.__learning_rate * numerical_derivative(f, self.__w)\n",
    "      self.__b -= self.__learning_rate * numerical_derivative(f, self.__b)\n",
    "      if(step %400==0):\n",
    "        print(\"step = \",step, \"에러 값 = \", self.error_val())\n",
    "  #예측 함수\n",
    "  def predict(self, input_data):\n",
    "    z=np.dot(input_data, self.__w) + self.__b\n",
    "    y=sigmoid(z)\n",
    "    if y > 0.5:\n",
    "      result = 1\n",
    "    else:\n",
    "      result = 0\n",
    "    return y, result\n",
    "\n",
    "\n",
    "# AND\n",
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,0,0,1])\n",
    "AND_g=LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "AND_g.train()\n",
    "print(AND_g.name, '\\n')\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "  (sigmoid_val, logical_val)=AND_g.predict(input_data)\n",
    "  print(input_data, \"=\", logical_val, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# NAND\n",
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([1,1,1,0])\n",
    "NAND_g=LogicGate(\"NAND_GATE\", xdata, tdata)\n",
    "NAND_g.train()\n",
    "print(NAND_g.name, '\\n')\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "  (sigmoid_val, logical_val)=NAND_g.predict(input_data)\n",
    "  print(input_data, \"=\", logical_val, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# OR\n",
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,1])\n",
    "OR_g=LogicGate(\"OR_GATE\", xdata, tdata)\n",
    "OR_g.train()\n",
    "print(OR_g.name, '\\n')\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "  (sigmoid_val, logical_val)=OR_g.predict(input_data)\n",
    "  print(input_data, \"=\", logical_val, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# XOR 계산하기\n",
    "input_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "s1=[] #NAND\n",
    "s2=[] #OR\n",
    "new_input_data=[] #AND 입력\n",
    "final_output=[] #AND 출력\n",
    "for index in range(len(input_data)):\n",
    "  s1=NAND_g.predict(input_data[index])\n",
    "  s2=OR_g.predict(input_data[index])\n",
    "  new_input_data.append(s1[-1])\n",
    "  new_input_data.append(s2[-1])\n",
    "  (sigmoid_val, logical_val)=AND_g.predict(np.array(new_input_data))\n",
    "  final_output.append(logical_val)\n",
    "  new_input_data=[] #AND 입력 초기화\n",
    "for index in range(len(input_data)):\n",
    "  print(input_data[index], \"=\", final_output[index], end='')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903da86-cf14-41a4-8b2b-a343c9ef57a4",
   "metadata": {
    "id": "c903da86-cf14-41a4-8b2b-a343c9ef57a4"
   },
   "source": [
    "## 딥러닝 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc56b95-f244-4b83-8612-f907896bf31f",
   "metadata": {
    "id": "ddc56b95-f244-4b83-8612-f907896bf31f",
    "outputId": "815335d1-3ab0-4f45-ab3b-b2262db0489e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial W2 =  [[0.15497813 0.37606227 0.05464317 0.73416074 0.13254254 0.56784939]\n",
      " [0.97675137 0.29971758 0.22062862 0.77747002 0.31123737 0.25684498]] b2 =  [0.2515533  0.63807937 0.10719994 0.45994386 0.79376504 0.3674299 ] W3 =  [[0.54904977]\n",
      " [0.60140594]\n",
      " [0.62778196]\n",
      " [0.89200565]\n",
      " [0.94255703]\n",
      " [0.52393964]] b3 =  [0.49932258] error_val =  6.875613913762543\n",
      "step =  0 W2 =  [[0.14683811 0.36666287 0.04040453 0.72536372 0.11716185 0.55907607]\n",
      " [0.96845546 0.29028819 0.20632401 0.76860408 0.29574055 0.24807265]] b2 =  [0.23074036 0.61597721 0.07843224 0.43131962 0.75938887 0.34685902] W3 =  [[0.42304779]\n",
      " [0.46813677]\n",
      " [0.52530096]\n",
      " [0.75421848]\n",
      " [0.80798704]\n",
      " [0.39849859]] b3 =  [0.32191781] error_val =  5.558590974623474\n",
      "step =  400 W2 =  [[-0.04168447  0.33571296  0.00942622  1.89483371  0.12401488  0.54774569]\n",
      " [ 0.9934384   0.23623135  0.17111474  1.92089366  0.25690169  0.15024522]] b2 =  [0.19062897 0.57099887 0.01113855 0.17605374 0.66896169 0.29623519] W3 =  [[-0.43480466]\n",
      " [-0.28575149]\n",
      " [-0.09443119]\n",
      " [ 1.74151898]\n",
      " [ 0.00701071]\n",
      " [-0.35052476]] b3 =  [-0.66966497] error_val =  2.5808040746891256\n",
      "step =  800 W2 =  [[-0.18529016  0.93609289  0.55325999  4.48720097  0.36516398  1.63983373]\n",
      " [ 2.20341962  0.33254098  0.56073865  4.62198713  0.43533776  0.13453795]] b2 =  [-0.33992007  0.05111945 -0.16983096 -1.09565647  0.53855977 -0.47903053] W3 =  [[-2.09326495]\n",
      " [-1.18919847]\n",
      " [-0.80321067]\n",
      " [ 5.47199714]\n",
      " [-0.47434931]\n",
      " [-1.87684772]] b3 =  [-0.47524372] error_val =  1.4880563232748598\n",
      "step =  1200 W2 =  [[-1.10051803  1.76817637  1.13560134  5.86058317  0.54932696  2.84460199]\n",
      " [ 3.94246007  0.40617081  0.85524271  5.98389409  0.52112617  0.68348085]] b2 =  [-0.20930336 -1.09714803 -1.1421157  -2.11007474  0.23914472 -2.16354443] W3 =  [[-3.99922918]\n",
      " [-2.35106533]\n",
      " [-1.85281894]\n",
      " [ 8.7741694 ]\n",
      " [-0.74281998]\n",
      " [-3.96997574]] b3 =  [0.07167928] error_val =  0.48226254730256446\n",
      "step =  1600 W2 =  [[-1.97684529  2.26491268  1.61400694  6.3295105   0.66569589  3.15639355]\n",
      " [ 4.5742693   0.51783845  0.93490481  6.5514311   0.4446873   1.57198799]] b2 =  [ 0.60542185 -1.67378188 -1.74465899 -2.4588668   0.10112229 -3.42677296] W3 =  [[-4.78696592]\n",
      " [-3.06797443]\n",
      " [-2.4748522 ]\n",
      " [10.35626817]\n",
      " [-0.86032028]\n",
      " [-5.23857061]] b3 =  [0.20415458] error_val =  0.17298672325650327\n",
      "step =  2000 W2 =  [[-2.43623022  2.52197339  1.89410702  6.52385614  0.74013929  3.39368173]\n",
      " [ 4.80958165  0.58396446  0.97832136  6.81270748  0.365189    2.04599655]] b2 =  [ 1.01962215 -1.96288933 -2.04969469 -2.62831801  0.03507899 -4.06028628] W3 =  [[-5.14602593]\n",
      " [-3.44105834]\n",
      " [-2.806883  ]\n",
      " [11.17196586]\n",
      " [-0.90766058]\n",
      " [-5.95076711]] b3 =  [0.26847221] error_val =  0.09225150040559171\n",
      "step =  2400 W2 =  [[-2.72290276  2.66968965  2.06590839  6.64054374  0.78955436  3.56532298]\n",
      " [ 4.93927161  0.63426567  1.0146484   6.97227309  0.30229462  2.32111838]] b2 =  [ 1.26636673e+00 -2.14488575e+00 -2.23946434e+00 -2.73984478e+00\n",
      " -1.75487920e-03 -4.43980184e+00] W3 =  [[-5.37814019]\n",
      " [-3.66995971]\n",
      " [-3.01686749]\n",
      " [11.70708088]\n",
      " [-0.94075847]\n",
      " [-6.40466036]] b3 =  [0.29844551] error_val =  0.0609838516897454\n",
      "step =  2800 W2 =  [[-2.9254482   2.76818627  2.18566306  6.72293792  0.82646002  3.69621069]\n",
      " [ 5.02594262  0.67525384  1.04525689  7.0859396   0.25082075  2.5051481 ]] b2 =  [ 1.43607401 -2.27668477 -2.37507871 -2.82167001 -0.02507558 -4.70209122] W3 =  [[-5.55065695]\n",
      " [-3.83104477]\n",
      " [-3.16746861]\n",
      " [12.10427633]\n",
      " [-0.96836956]\n",
      " [-6.73054734]] b3 =  [0.31272923] error_val =  0.04504685024358522\n",
      "step =  3200 W2 =  [[-3.07970543  2.84049438  2.27644473  6.78623801  0.85613318  3.80099761]\n",
      " [ 5.09006853  0.70998662  1.07143387  7.17394772  0.20709294  2.63980431]] b2 =  [ 1.56314883 -2.37986672 -2.4799689  -2.88560499 -0.04104137 -4.89932105] W3 =  [[-5.68806581]\n",
      " [-3.95417605]\n",
      " [-3.28401664]\n",
      " [12.42021734]\n",
      " [-0.9928086 ]\n",
      " [-6.98238214]] b3 =  [0.31916457] error_val =  0.035527461851552214\n",
      "step =  3600 W2 =  [[-3.20309427  2.89701988  2.34913279  6.83743496  0.88112606  3.88792599]\n",
      " [ 5.14053052  0.7402094   1.09421354  7.24565132  0.16891726  2.74429472]] b2 =  [ 1.66361667 -2.46463089 -2.56522108 -2.93770143 -0.05251736 -5.05585216] W3 =  [[-5.80219854]\n",
      " [-4.05340151]\n",
      " [-3.37874298]\n",
      " [12.68270424]\n",
      " [-1.01504194]\n",
      " [-7.18652435]] b3 =  [0.32131962] error_val =  0.029243113541307306\n",
      "step =  4000 W2 =  [[-3.30524162  2.9431619   2.40956205  6.88030125  0.9028427   3.96195238]\n",
      " [ 5.18190457  0.76701646  1.11434783  7.3060981   0.13492017  2.82876157]] b2 =  [ 1.74607918 -2.53656089 -2.63689113 -2.98144244 -0.06102392 -5.18478495] W3 =  [[-5.89973169]\n",
      " [-4.13630362]\n",
      " [-3.45837867]\n",
      " [12.90736359]\n",
      " [-1.03559315]\n",
      " [-7.35759311]] b3 =  [0.32099154] error_val =  0.02480155113806508\n",
      "step =  4400 W2 =  [[-3.39197372  2.98202282  2.46117989  6.9170972   0.92213313  4.0262566 ]\n",
      " [ 5.21683319  0.79114039  1.13237892  7.35831201  0.10419043  2.89911717]] b2 =  [ 1.81563403 -2.59903666 -2.698631   -3.01900127 -0.06744909 -5.29389558] W3 =  [[-5.98481971]\n",
      " [-4.20739747]\n",
      " [-3.52699146]\n",
      " [13.1038368 ]\n",
      " [-1.05479197]\n",
      " [-7.50447137]] b3 =  [0.31916227] error_val =  0.02150380722442029\n",
      "step =  4800 W2 =  [[-3.46706128  3.01552707  2.50617701  6.94928101  0.93955017  4.08298956]\n",
      " [ 5.24697085  0.81309662  1.14870393  7.40424499  0.07609276  2.95907027]] b2 =  [ 1.87552895 -2.65425756 -2.7528061  -3.05181779 -0.07235012 -5.38814528] W3 =  [[-6.06022896]\n",
      " [-4.26957354]\n",
      " [-3.58721585]\n",
      " [13.27848783]\n",
      " [-1.07286599]\n",
      " [-7.63293425]] b3 =  [0.31640294] error_val =  0.018962518213224352\n",
      "step =  5200 W2 =  [[-3.53307342  3.0449408   2.54602598  6.97784668  0.95547352  4.13366958]\n",
      " [ 5.27341772  0.83326218  1.16362001  7.44522929  0.05016606  3.01108183]] b2 =  [ 1.92794996 -2.70373453 -2.80103332 -3.08089145 -0.07609655 -5.47087786] W3 =  [[-6.12789604]\n",
      " [-4.32478728]\n",
      " [-3.64085088]\n",
      " [13.43573731]\n",
      " [-1.08998203]\n",
      " [-7.74693595]] b3 =  [0.31306213] error_val =  0.016946466748775528\n",
      "step =  5600 W2 =  [[-3.59183309  3.07113688  2.58176149  7.00350128  0.97017546  4.17940623]\n",
      " [ 5.29694024  0.85192163  1.1773542   7.48221445  0.02606445  3.05685885]] b2 =  [ 1.97443329 -2.74855032 -2.84446533 -3.10694225 -0.07894442 -5.54444611] W3 =  [[-6.18923017]\n",
      " [-4.37442026]\n",
      " [-3.68917745]\n",
      " [13.57878109]\n",
      " [-1.10626764]\n",
      " [-7.84929668]] b3 =  [0.30936067] error_val =  0.015309433987791955\n",
      "step =  6000 W2 =  [[-3.64467703e+00  3.09474019e+00  2.61413709e+00  7.02676520e+00\n",
      "   9.83858043e-01  4.22103379e+00]\n",
      " [ 5.31809253e+00  8.69295307e-01  1.19008345e+00  7.51590090e+00\n",
      "   3.52139516e-03  3.09762853e+00]] b2 =  [ 2.01609661 -2.78950739 -2.88395193 -3.13050487 -0.0810775  -5.61056385] W3 =  [[-6.24528896]\n",
      " [-4.41948321]\n",
      " [-3.73313867]\n",
      " [13.71000486]\n",
      " [-1.12182339]\n",
      " [-7.94209533]] b3 =  [0.3054426] error_val =  0.013954581907108278\n",
      "step =  6400 W2 =  [[-3.69261242  3.11621218  2.64371792  7.04803224  0.99667555  4.25919477]\n",
      " [ 5.33728745  0.88555751  1.20194805  7.54682012 -0.01767321  3.13429956]] b2 =  [ 2.05377661 -2.82721705 -2.92013721 -3.15198654 -0.08263161 -5.67051553] W3 =  [[-6.29688639]\n",
      " [-4.46073707]\n",
      " [-3.77344848]\n",
      " [13.83123705]\n",
      " [-1.13673052]\n",
      " [-8.02690649]] b3 =  [0.30140395] error_val =  0.012815307643156757\n",
      "step =  6800 W2 =  [[-3.73641561  3.13590264  2.67093837  7.06760737  1.00874857  4.29439403]\n",
      " [ 5.3548405   0.90084861  1.21306102  7.57538488 -0.03768815  3.16756164]] b2 =  [ 2.08811477 -2.86215578 -2.95352067 -3.17170409 -0.08370962 -5.72528695] W3 =  [[-6.34466233]\n",
      " [-4.49876861]\n",
      " [-3.81065994]\n",
      " [13.94391011]\n",
      " [-1.15105591]\n",
      " [-8.10495023]] b3 =  [0.29730985] error_val =  0.011844339391442308\n",
      "step =  7200 W2 =  [[-3.77669677  3.15408263  2.69613934  7.08573145  1.02017323  4.32703522]\n",
      " [ 5.37099784  0.91528344  1.22351467  7.60192213 -0.05666126  3.1979494 ]] b2 =  [ 2.11961293 -2.89470218 -2.98449729 -3.18990857 -0.08439109 -5.77565015] W3 =  [[-6.38912884]\n",
      " [-4.53403949]\n",
      " [-3.84521003]\n",
      " [14.04916744]\n",
      " [-1.16485549]\n",
      " [-8.17719037]] b3 =  [0.29320491] error_val =  0.011007221175119174\n",
      "step =  7600 W2 =  [[-3.81394356  3.17096621  2.71959318  7.1025979   1.0310275   4.35744599]\n",
      " [ 5.38595513  0.92895718  1.23338529  7.62669526 -0.07470666  3.22588477]] b2 =  [ 2.14867058 -2.92516211 -3.01338469 -3.2068021  -0.08473865 -5.82222035] W3 =  [[-6.43070205]\n",
      " [-4.56691938]\n",
      " [-3.87744983]\n",
      " [14.14793638]\n",
      " [-1.17817666]\n",
      " [-8.24440107]] b3 =  [0.28911995] error_val =  0.010278259495196585\n",
      "step =  8000 W2 =  [[-3.84855141  3.18672525  2.74152086  7.11836435  1.04137554  4.38589575]\n",
      " [ 5.39987025  0.94194967  1.24273669  7.64991957 -0.09192002  3.2517061 ]] b2 =  [ 2.17561057 -2.95378622 -3.04044198 -3.22254965 -0.08480238 -5.8654952 ] W3 =  [[-6.46972466]\n",
      " [-4.59770872]\n",
      " [-3.9076656 ]\n",
      " [14.24097956]\n",
      " [-1.19106002]\n",
      " [-8.30721317]] b3 =  [0.2850762] error_val =  0.009637913060929836\n",
      "(0, array([0.00252463]))\n",
      "(1, array([0.99862676]))\n",
      "(1, array([0.99661058]))\n",
      "(0, array([0.00233839]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 시그모이드 구하는 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 수치 미분 함수\n",
    "def numerical_derivative(f, input_data):\n",
    "    delta_x = 1e-4\n",
    "    ret = np.zeros_like(input_data)\n",
    "    it = np.nditer(input_data, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp = input_data[idx]\n",
    "        input_data[idx] = float(tmp) + delta_x\n",
    "        fx1 = f(input_data)\n",
    "        input_data[idx] = float(tmp) - delta_x\n",
    "        fx2 = f(input_data)\n",
    "        ret[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        input_data[idx] = tmp\n",
    "        it.iternext()\n",
    "    return ret\n",
    "\n",
    "class LogicGate:\n",
    "    def __init__(self, gate_name, x_data, t_data):\n",
    "        self.name = gate_name\n",
    "        # 입력 데이터\n",
    "        self.__x_data = x_data\n",
    "        self.__t_data = t_data\n",
    "        # 임의의 W2, b2, W3, b3 준비\n",
    "        self.__W2 = np.random.rand(2, 6)\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        self.__W3 = np.random.rand(6, 1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        self.__learning_rate = 1e-1\n",
    "        self.loss_func = self.__feed_forward\n",
    "    \n",
    "    # feed_forward 함수로, 에러를 찾아줌\n",
    "    def __feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        # 입력층 -> 은닉층\n",
    "        z2 = np.dot(self.__x_data, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        # 은닉층 -> 출력층\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = sigmoid(z3)\n",
    "        # 크로스 엔트로피로 에러를 측정\n",
    "        return -np.sum(self.__t_data * np.log(y + delta) + (1 - self.__t_data) * np.log(1 - y + delta))\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x: self.__feed_forward()\n",
    "        print(\"Initial W2 = \", self.__W2, \"b2 = \", self.__b2, \"W3 = \", self.__W3, \"b3 = \", self.__b3, \"error_val = \", self.loss_func())\n",
    "        for step in range(8001):\n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "            if step % 400 == 0:\n",
    "                print(\"step = \", step, \"W2 = \", self.__W2, \"b2 = \", self.__b2, \"W3 = \", self.__W3, \"b3 = \", self.__b3, \"error_val = \", self.loss_func())\n",
    "                \n",
    "    def predict(self, x_data):\n",
    "        z2 = np.dot(x_data, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        pro = sigmoid(z3)\n",
    "        if pro < 0.5:\n",
    "            return 0, pro\n",
    "        return 1, pro\n",
    "\n",
    "# XOR 데이터\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape([4, 2])\n",
    "y_data = np.array([0, 1, 1, 0]).reshape([4, 1])\n",
    "\n",
    "# 학습\n",
    "XOR_Gate = LogicGate(\"XOR_Gate\", x_data, y_data)\n",
    "XOR_Gate.train()\n",
    "\n",
    "# 출력\n",
    "print(XOR_Gate.predict([0, 0]))\n",
    "print(XOR_Gate.predict([1, 0]))\n",
    "print(XOR_Gate.predict([0, 1]))\n",
    "print(XOR_Gate.predict([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b10731-a6bb-4313-8544-1b42d34c3f0d",
   "metadata": {
    "id": "50b10731-a6bb-4313-8544-1b42d34c3f0d",
    "outputId": "5b5f2182-7626-45c2-e4a5-1996561de5c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[0.42894247]] ,W.shape (1, 1) ,b= [0.43410131] ,b.shape (1,)\n",
      "초기 에러 값 = 5.846379299875832 초기 W 값 = [[0.42894247]] 초기 b 값 = [0.43410131]\n",
      "step =  0 에러 값 = 3.4513899309077245 W 값 = [[0.58852905]] b 값 = [0.47010754]\n",
      "step =  500 에러 값 = 0.0010104699239588577 W 값 = [[1.02064232]] b 값 = [0.92549293]\n",
      "step =  1000 에러 값 = 3.2404068532644366e-05 W 값 = [[1.00369655]] b 값 = [0.98665755]\n",
      "step =  1500 에러 값 = 1.039143899853774e-06 W 값 = [[1.00066196]] b 값 = [0.99761068]\n",
      "step =  2000 에러 값 = 3.3323594644125554e-08 W 값 = [[1.00011854]] b 값 = [0.99957213]\n",
      "step =  2500 에러 값 = 1.068631553483198e-09 W 값 = [[1.00002123]] b 값 = [0.99992338]\n",
      "step =  3000 에러 값 = 3.426921403000274e-11 W 값 = [[1.0000038]] b 값 = [0.99998628]\n",
      "step =  3500 에러 값 = 1.0989559740584496e-12 W 값 = [[1.00000068]] b 값 = [0.99999754]\n",
      "step =  4000 에러 값 = 3.524166709683615e-14 W 값 = [[1.00000012]] b 값 = [0.99999956]\n",
      "step =  4500 에러 값 = 1.130140917962247e-15 W 값 = [[1.00000002]] b 값 = [0.99999992]\n",
      "step =  5000 에러 값 = 3.6241713809220476e-17 W 값 = [[1.]] b 값 = [0.99999999]\n",
      "step =  5500 에러 값 = 1.1622101823160593e-18 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  6000 에러 값 = 3.727018607240343e-20 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  6500 에러 값 = 1.1951988148999578e-21 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  7000 에러 값 = 3.8326598120769824e-23 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  7500 에러 값 = 1.231279896620556e-24 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  8000 에러 값 = 3.979964983325575e-26 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  8500 에러 값 = 1.2631339422011994e-27 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  9000 에러 값 = 9.517606821491508e-29 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  9500 에러 값 = 9.517606821491508e-29 W 값 = [[1.]] b 값 = [1.]\n",
      "step =  10000 에러 값 = 9.517606821491508e-29 W 값 = [[1.]] b 값 = [1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패키지 임포트\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터 셋 생성\n",
    "X=np.array(\n",
    "    [1,2,3,4,5]\n",
    ").reshape(5,1)\n",
    "X\n",
    "\n",
    "\n",
    "y=np.array(\n",
    "    [2,3,4,5,6]\n",
    ").reshape(5,1)\n",
    "y\n",
    "\n",
    "# W,b 초기화\n",
    "W=np.random.rand(1,1)\n",
    "b=np.random.rand(1)\n",
    "print(\n",
    "    \"W=\",W,\n",
    "    \",W.shape\",W.shape,\n",
    "    \",b=\",b,\n",
    "    \",b.shape\",b.shape\n",
    ")\n",
    "\n",
    "# 손실함수 정의\n",
    "def loss_func(x, t):\n",
    "  # H(x)를 정의 - 행렬 계산\n",
    "  y=np.dot(x,W)+b\n",
    "  return np.sum((t - y)**2) /len(x)\n",
    "\n",
    "# 수치미분 함수 정의\n",
    "def numerical_derivative(fx, input_list):\n",
    "  delta_x=1e-4 # 1* 0.00001\n",
    "  ret=np.zeros_like(input_list)\n",
    "  it=np.nditer(input_list, flags=['multi_index'], op_flags=['readwrite'])\n",
    "  while not it.finished:\n",
    "    i=it.multi_index\n",
    "    tmp=input_list[i]\n",
    "    input_list[i]=float(tmp) - delta_x\n",
    "    f1=fx(input_list)\n",
    "    input_list[i]=float(tmp) + delta_x\n",
    "    f2=fx(input_list)\n",
    "    ret[i]=(f2-f1) / (delta_x*2)\n",
    "    input_list[i]=tmp\n",
    "    it.iternext()\n",
    "  return ret\n",
    "\n",
    "\n",
    "# 손실함수 계산- 에러 값 계산\n",
    "def error_val(x, t):\n",
    "  # H(x)를 정의 - 행렬 계산\n",
    "  y=np.dot(x,W)+b\n",
    "  return np.sum((t - y)**2) /len(x)\n",
    "\n",
    "\n",
    "# W,b 업데이트 수행 - 학습\n",
    "#학습율\n",
    "learning_rate=1e-2\n",
    "f = lambda x: loss_func(X, y)\n",
    "print(\n",
    "    \"초기 에러 값 =\", error_val(X,y),\n",
    "    \"초기 W 값 =\",W,\n",
    "    \"초기 b 값 =\",b\n",
    ")\n",
    "for step in range(10001):\n",
    "  # W,b 를 경사하강으로 업데이트\n",
    "  W -= numerical_derivative(f,W) * learning_rate\n",
    "  b -= numerical_derivative(f,b) * learning_rate\n",
    "  if step % 500 == 0:\n",
    "    print(\n",
    "        \"step = \", step,\n",
    "        \"에러 값 =\", error_val(X,y),\n",
    "        \"W 값 =\",W,\n",
    "        \"b 값 =\",b\n",
    "    )\n",
    "\n",
    "\n",
    "# 학습된 결과로 현장 적용 후 예측 함수 정의\n",
    "def predict(x):\n",
    "  y=np.dot(x,W)+b\n",
    "  return y\n",
    "\n",
    "predict(47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71767c-441b-4278-ab7d-b0e33725f419",
   "metadata": {
    "id": "0c71767c-441b-4278-ab7d-b0e33725f419"
   },
   "source": [
    "# deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8a4a7-6e07-4f9c-b362-67e42dfd14bc",
   "metadata": {
    "id": "bbd8a4a7-6e07-4f9c-b362-67e42dfd14bc"
   },
   "source": [
    "## 텐서플로  익히기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed24d6fc-9203-4a37-bdb3-15e9480b65f4",
   "metadata": {
    "id": "ed24d6fc-9203-4a37-bdb3-15e9480b65f4",
    "outputId": "b0c15d1e-12dc-41c0-df65-89efdb2ed9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.compat.v1.Session() as sess:\n",
    "   helloworld = tf.constant(\"Hello World!\")\n",
    "   print(sess.run(helloworld))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0vV3GZGH04Y",
   "metadata": {
    "id": "s0vV3GZGH04Y"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0UjWExH1B4",
   "metadata": {
    "id": "de0UjWExH1B4"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "j-ADpoOtRgO2",
   "metadata": {
    "id": "j-ADpoOtRgO2"
   },
   "source": [
    "# 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Ux2a8GmC7sua",
   "metadata": {
    "id": "Ux2a8GmC7sua"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "T75CiRkI7sua",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "T75CiRkI7sua",
    "outputId": "1fec735a-a8d9-4a2d-dc5a-7ac1a6224cb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ncozDaUeP4iN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncozDaUeP4iN",
    "outputId": "bd48c615-27dc-46fc-bc5d-661fe40b13e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "x=tf.constant(3)\n",
    "y=x**2\n",
    "\n",
    "# 세션 객체 생성\n",
    "# sess=tf.Session()\n",
    "\n",
    "# 세션 객체를 이용해서 텐서를 사용\n",
    "# print(sess.run(x))\n",
    "# print(sess.run(y))\n",
    "\n",
    "# sess.close()\n",
    "# sess.close()\n",
    "\n",
    "tf.print(x)\n",
    "tf.print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sFXocppVENs2",
   "metadata": {
    "id": "sFXocppVENs2"
   },
   "source": [
    "### 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "wi2ak581Sa54",
   "metadata": {
    "id": "wi2ak581Sa54",
    "outputId": "8b819421-5914-4a19-eb77-6ae25d83e48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "tf.Tensor(\n",
      "[[0.10273719 0.4762597  0.23663199]\n",
      " [0.30076706 0.73779476 0.17305231]], shape=(2, 3), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "a=tf.random.uniform([2,3],0,1)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "E--VBxtqScvA",
   "metadata": {
    "id": "E--VBxtqScvA",
    "outputId": "579521a1-18ee-42fa-f7f1-3def099a966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow로 생성한 텐서:\n",
      " tf.Tensor(\n",
      "[[0.8067726  0.86146724 0.80488276]\n",
      " [0.00330651 0.27930796 0.48967326]], shape=(2, 3), dtype=float32) \n",
      "\n",
      "numpy로 생성한 ndarray:\n",
      " [[0.04154067 0.72644253 0.10191643]\n",
      " [0.83466477 0.70079021 0.61053252]] \n",
      "\n",
      "덧셈 결과:\n",
      " tf.Tensor(\n",
      "[[0.8483133  1.5879097  0.9067992 ]\n",
      " [0.83797127 0.9800982  1.1002058 ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "t=tf.random.uniform([2,3],0,1)\n",
    "n=np.random.uniform(0,1,[2,3])\n",
    "print(\"tensorflow로 생성한 텐서:\\n\",t,\"\\n\")\n",
    "print(\"numpy로 생성한 ndarray:\\n\",n,\"\\n\")\n",
    "\n",
    "res=t+n # 텐서 t와 ndarray n의 덧셈\n",
    "print(\"덧셈 결과:\\n\",res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Beil24jxHkzB",
   "metadata": {
    "id": "Beil24jxHkzB"
   },
   "source": [
    "## 텐서 기본 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ODCtR_mHkzB",
   "metadata": {
    "id": "8ODCtR_mHkzB",
    "outputId": "dc7986f2-5f82-499b-9fca-f7217dbcdf17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "0 0.9993008 [0.78949046] [1.0288727]\n",
      "20 4.306994e-05 [1.0021161] [1.0886061]\n",
      "40 1.9811618e-05 [1.0028756] [1.089601]\n",
      "60 1.7304252e-05 [1.0026914] [1.0902828]\n",
      "80 1.511044e-05 [1.0025152] [1.0909193]\n",
      "100 1.3196812e-05 [1.0023504] [1.091514]\n",
      "120 1.1524165e-05 [1.0021966] [1.0920697]\n",
      "140 1.0064541e-05 [1.0020528] [1.092589]\n",
      "160 8.789874e-06 [1.0019182] [1.0930742]\n",
      "180 7.676485e-06 [1.0017927] [1.0935277]\n",
      "200 6.7038854e-06 [1.0016752] [1.0939516]\n",
      "220 5.8540836e-06 [1.0015656] [1.0943477]\n",
      "240 5.1129327e-06 [1.001463] [1.0947177]\n",
      "260 4.4653216e-06 [1.0013673] [1.0950634]\n",
      "280 3.900122e-06 [1.0012778] [1.0953867]\n",
      "300 3.4061547e-06 [1.0011942] [1.0956887]\n",
      "320 2.9746375e-06 [1.001116] [1.095971]\n",
      "340 2.5974934e-06 [1.0010428] [1.0962348]\n",
      "360 2.2691063e-06 [1.0009745] [1.0964812]\n",
      "380 1.9816384e-06 [1.0009109] [1.0967118]\n",
      "400 1.7305067e-06 [1.0008513] [1.0969269]\n",
      "420 1.5113512e-06 [1.0007955] [1.0971282]\n",
      "440 1.3200312e-06 [1.0007435] [1.097316]\n",
      "460 1.1527851e-06 [1.0006948] [1.0974919]\n",
      "480 1.0066897e-06 [1.0006492] [1.0976561]\n",
      "500 8.7915276e-07 [1.0006068] [1.0978096]\n",
      "520 7.678078e-07 [1.0005671] [1.0979528]\n",
      "540 6.7060967e-07 [1.00053] [1.098087]\n",
      "560 5.8575466e-07 [1.0004953] [1.0982121]\n",
      "580 5.115504e-07 [1.0004629] [1.0983292]\n",
      "600 4.4671006e-07 [1.0004325] [1.0984386]\n",
      "620 3.9006468e-07 [1.0004042] [1.0985408]\n",
      "640 3.4086753e-07 [1.0003777] [1.0986363]\n",
      "660 2.975858e-07 [1.0003531] [1.0987256]\n",
      "680 2.5997284e-07 [1.00033] [1.0988089]\n",
      "700 2.2711883e-07 [1.0003083] [1.0988868]\n",
      "720 1.9819159e-07 [1.0002882] [1.0989598]\n",
      "740 1.7311876e-07 [1.0002693] [1.0990278]\n",
      "760 1.5129568e-07 [1.0002518] [1.0990913]\n",
      "780 1.3214559e-07 [1.0002351] [1.0991507]\n",
      "800 1.1542171e-07 [1.00022] [1.0992063]\n",
      "820 1.0088638e-07 [1.0002055] [1.099258]\n",
      "840 8.8093884e-08 [1.000192] [1.0993067]\n",
      "860 7.689982e-08 [1.0001795] [1.099352]\n",
      "880 6.7232044e-08 [1.0001676] [1.0993943]\n",
      "900 5.870811e-08 [1.0001568] [1.099434]\n",
      "920 5.12449e-08 [1.0001466] [1.099471]\n",
      "940 4.4792387e-08 [1.000137] [1.0995054]\n",
      "960 3.909622e-08 [1.0001279] [1.0995378]\n",
      "980 3.4200866e-08 [1.0001196] [1.0995681]\n",
      "1000 2.9790874e-08 [1.0001118] [1.0995965]\n",
      "1020 2.6057853e-08 [1.0001047] [1.0996227]\n",
      "1040 2.2825361e-08 [1.0000976] [1.0996469]\n",
      "1060 1.9913182e-08 [1.0000912] [1.0996703]\n",
      "1080 1.743524e-08 [1.0000854] [1.0996917]\n",
      "1100 1.5218529e-08 [1.0000799] [1.0997117]\n",
      "1120 1.3266799e-08 [1.0000747] [1.0997307]\n",
      "1140 1.1650604e-08 [1.0000699] [1.0997478]\n",
      "1160 1.0156304e-08 [1.0000651] [1.0997645]\n",
      "1180 8.86962e-09 [1.0000608] [1.09978]\n",
      "1200 7.7473485e-09 [1.000057] [1.0997943]\n",
      "1220 6.7305903e-09 [1.000053] [1.0998083]\n",
      "1240 5.9123635e-09 [1.0000498] [1.0998203]\n",
      "1260 5.1588813e-09 [1.0000465] [1.0998322]\n",
      "1280 4.5000887e-09 [1.0000435] [1.0998431]\n",
      "1300 3.9648627e-09 [1.0000409] [1.0998527]\n",
      "1320 3.4767254e-09 [1.0000384] [1.0998622]\n",
      "1340 3.0069827e-09 [1.0000358] [1.0998718]\n",
      "1360 2.675688e-09 [1.0000334] [1.099879]\n",
      "1380 2.3630946e-09 [1.0000314] [1.0998862]\n",
      "1400 2.0864832e-09 [1.0000293] [1.0998933]\n",
      "1420 1.8175456e-09 [1.0000274] [1.0999005]\n",
      "1440 1.5672527e-09 [1.0000255] [1.0999076]\n",
      "1460 1.335593e-09 [1.0000236] [1.0999144]\n",
      "1480 1.1909833e-09 [1.0000223] [1.0999192]\n",
      "1500 1.0586518e-09 [1.000021] [1.099924]\n",
      "1520 9.230575e-10 [1.0000197] [1.0999287]\n",
      "1540 8.077222e-10 [1.0000184] [1.0999335]\n",
      "1560 6.994014e-10 [1.0000172] [1.0999383]\n",
      "1580 5.9009153e-10 [1.0000159] [1.099943]\n",
      "1600 5.0727067e-10 [1.0000147] [1.0999472]\n",
      "1620 4.5820342e-10 [1.000014] [1.0999497]\n",
      "1640 4.1688963e-10 [1.0000134] [1.0999521]\n",
      "1660 3.7804285e-10 [1.0000126] [1.0999545]\n",
      "1680 3.3633113e-10 [1.000012] [1.0999569]\n",
      "1700 3.0483988e-10 [1.0000113] [1.0999593]\n",
      "1720 2.6535646e-10 [1.0000107] [1.0999616]\n",
      "1740 2.3501343e-10 [1.00001] [1.099964]\n",
      "1760 2.0941116e-10 [1.0000093] [1.0999664]\n",
      "1780 1.7877255e-10 [1.0000087] [1.0999688]\n",
      "1800 1.5231763e-10 [1.0000081] [1.0999712]\n",
      "1820 1.2892087e-10 [1.0000075] [1.0999736]\n",
      "1840 1.0545591e-10 [1.0000067] [1.099976]\n",
      "1860 8.619736e-11 [1.0000062] [1.0999783]\n",
      "1880 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1900 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1920 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1940 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1960 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1980 7.504468e-11 [1.0000058] [1.0999795]\n",
      "2000 7.504468e-11 [1.0000058] [1.0999795]\n",
      "[6.1000085]\n",
      "[3.5999942]\n",
      "[2.5999885 4.6      ]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = x * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    _cost, _W, _b, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "            feed_dict={x: [1, 2, 3, 4, 5], y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, _cost, _W, _b)\n",
    "\n",
    "print(sess.run(hypothesis, feed_dict={x: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={x: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={x: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "OM906N88HkzC",
   "metadata": {
    "id": "OM906N88HkzC",
    "outputId": "da4e01bf-4574-4947-d1a9-becec6d2531f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 43.741093 \t [-0.71942544] \t [-0.02413182]\n",
      "20 \t 0.86226827 \t [1.5532498] \t [1.082198]\n",
      "40 \t 0.4307567 \t [1.7359571] \t [1.2641386]\n",
      "60 \t 0.3880254 \t [1.721243] \t [1.3544599]\n",
      "80 \t 0.3523816 \t [1.6892394] \t [1.4326268]\n",
      "100 \t 0.3200384 \t [1.657028] \t [1.5063668]\n",
      "120 \t 0.29066414 \t [1.6261673] \t [1.5765694]\n",
      "140 \t 0.26398587 \t [1.5967414] \t [1.6434659]\n",
      "160 \t 0.23975621 \t [1.568697] \t [1.7072182]\n",
      "180 \t 0.21775042 \t [1.5419703] \t [1.7679743]\n",
      "200 \t 0.1977644 \t [1.5164995] \t [1.8258749]\n",
      "220 \t 0.1796128 \t [1.4922261] \t [1.8810545]\n",
      "240 \t 0.1631272 \t [1.4690933] \t [1.933641]\n",
      "260 \t 0.14815465 \t [1.4470476] \t [1.983756]\n",
      "280 \t 0.13455655 \t [1.426038] \t [2.0315156]\n",
      "300 \t 0.12220632 \t [1.4060156] \t [2.0770311]\n",
      "320 \t 0.11098962 \t [1.3869343] \t [2.1204076]\n",
      "340 \t 0.10080254 \t [1.3687497] \t [2.1617455]\n",
      "360 \t 0.09155041 \t [1.3514197] \t [2.2011406]\n",
      "380 \t 0.08314758 \t [1.3349042] \t [2.2386837]\n",
      "400 \t 0.07551593 \t [1.319165] \t [2.274463]\n",
      "420 \t 0.0685849 \t [1.3041656] \t [2.30856]\n",
      "440 \t 0.062289882 \t [1.289871] \t [2.3410552]\n",
      "460 \t 0.056572754 \t [1.2762481] \t [2.3720229]\n",
      "480 \t 0.051380247 \t [1.2632656] \t [2.4015355]\n",
      "500 \t 0.046664417 \t [1.2508931] \t [2.4296608]\n",
      "520 \t 0.042381357 \t [1.2391021] \t [2.4564648]\n",
      "540 \t 0.038491424 \t [1.2278652] \t [2.482009]\n",
      "560 \t 0.03495848 \t [1.2171563] \t [2.5063527]\n",
      "580 \t 0.031749927 \t [1.2069509] \t [2.529552]\n",
      "600 \t 0.028835842 \t [1.197225] \t [2.5516605]\n",
      "620 \t 0.026189217 \t [1.1879563] \t [2.5727308]\n",
      "640 \t 0.023785492 \t [1.1791232] \t [2.5928106]\n",
      "660 \t 0.021602342 \t [1.1707051] \t [2.6119473]\n",
      "680 \t 0.019619565 \t [1.1626825] \t [2.6301847]\n",
      "700 \t 0.017818796 \t [1.1550369] \t [2.6475646]\n",
      "720 \t 0.016183289 \t [1.1477507] \t [2.6641278]\n",
      "740 \t 0.0146979615 \t [1.1408068] \t [2.6799126]\n",
      "760 \t 0.013348922 \t [1.1341896] \t [2.6949553]\n",
      "780 \t 0.012123711 \t [1.1278832] \t [2.7092912]\n",
      "800 \t 0.011010942 \t [1.1218733] \t [2.7229533]\n",
      "820 \t 0.01000036 \t [1.1161457] \t [2.7359734]\n",
      "840 \t 0.0090824915 \t [1.1106874] \t [2.7483816]\n",
      "860 \t 0.008248789 \t [1.1054853] \t [2.7602074]\n",
      "880 \t 0.007491691 \t [1.1005275] \t [2.7714767]\n",
      "900 \t 0.0068040565 \t [1.0958031] \t [2.7822165]\n",
      "920 \t 0.00617954 \t [1.0913008] \t [2.7924519]\n",
      "940 \t 0.005612332 \t [1.0870097] \t [2.8022065]\n",
      "960 \t 0.0050972193 \t [1.0829207] \t [2.8115022]\n",
      "980 \t 0.004629373 \t [1.0790236] \t [2.8203607]\n",
      "1000 \t 0.0042044935 \t [1.0753099] \t [2.8288028]\n",
      "1020 \t 0.0038185779 \t [1.0717707] \t [2.8368485]\n",
      "1040 \t 0.0034681114 \t [1.0683976] \t [2.8445158]\n",
      "1060 \t 0.0031498007 \t [1.0651833] \t [2.8518229]\n",
      "1080 \t 0.0028606926 \t [1.06212] \t [2.8587866]\n",
      "1100 \t 0.0025981308 \t [1.0592005] \t [2.865423]\n",
      "1120 \t 0.0023596787 \t [1.0564185] \t [2.8717475]\n",
      "1140 \t 0.0021431006 \t [1.0537671] \t [2.8777742]\n",
      "1160 \t 0.001946391 \t [1.0512403] \t [2.8835187]\n",
      "1180 \t 0.0017677402 \t [1.0488323] \t [2.888993]\n",
      "1200 \t 0.0016054908 \t [1.0465372] \t [2.89421]\n",
      "1220 \t 0.0014581388 \t [1.0443501] \t [2.8991816]\n",
      "1240 \t 0.0013243053 \t [1.0422659] \t [2.9039197]\n",
      "1260 \t 0.0012027639 \t [1.0402799] \t [2.9084349]\n",
      "1280 \t 0.001092372 \t [1.0383866] \t [2.9127378]\n",
      "1300 \t 0.0009921056 \t [1.0365826] \t [2.9168394]\n",
      "1320 \t 0.00090103265 \t [1.0348632] \t [2.920748]\n",
      "1340 \t 0.00081834063 \t [1.0332247] \t [2.9244723]\n",
      "1360 \t 0.0007432197 \t [1.0316633] \t [2.928022]\n",
      "1380 \t 0.0006750144 \t [1.0301753] \t [2.9314046]\n",
      "1400 \t 0.0006130549 \t [1.0287571] \t [2.9346282]\n",
      "1420 \t 0.00055678666 \t [1.0274057] \t [2.9377005]\n",
      "1440 \t 0.0005056754 \t [1.0261177] \t [2.9406285]\n",
      "1460 \t 0.00045926627 \t [1.0248902] \t [2.9434187]\n",
      "1480 \t 0.00041711374 \t [1.0237204] \t [2.946078]\n",
      "1500 \t 0.00037882596 \t [1.0226058] \t [2.948612]\n",
      "1520 \t 0.0003440569 \t [1.0215434] \t [2.951027]\n",
      "1540 \t 0.00031248078 \t [1.0205312] \t [2.9533286]\n",
      "1560 \t 0.00028379826 \t [1.019566] \t [2.955522]\n",
      "1580 \t 0.0002577497 \t [1.0186462] \t [2.9576123]\n",
      "1600 \t 0.00023410626 \t [1.0177703] \t [2.959603]\n",
      "1620 \t 0.00021261524 \t [1.0169353] \t [2.961502]\n",
      "1640 \t 0.00019309692 \t [1.0161394] \t [2.9633114]\n",
      "1660 \t 0.00017538067 \t [1.015381] \t [2.9650354]\n",
      "1680 \t 0.0001592818 \t [1.0146581] \t [2.9666789]\n",
      "1700 \t 0.00014466034 \t [1.0139692] \t [2.9682448]\n",
      "1720 \t 0.00013137987 \t [1.0133127] \t [2.9697373]\n",
      "1740 \t 0.00011932181 \t [1.0126871] \t [2.9711595]\n",
      "1760 \t 0.00010837513 \t [1.0120908] \t [2.9725146]\n",
      "1780 \t 9.842439e-05 \t [1.0115227] \t [2.9738064]\n",
      "1800 \t 8.9392444e-05 \t [1.0109811] \t [2.9750373]\n",
      "1820 \t 8.118679e-05 \t [1.010465] \t [2.9762104]\n",
      "1840 \t 7.373858e-05 \t [1.0099732] \t [2.9773283]\n",
      "1860 \t 6.697053e-05 \t [1.0095044] \t [2.9783938]\n",
      "1880 \t 6.0819908e-05 \t [1.0090579] \t [2.9794095]\n",
      "1900 \t 5.5236993e-05 \t [1.008632] \t [2.9803774]\n",
      "1920 \t 5.016575e-05 \t [1.0082263] \t [2.9812996]\n",
      "1940 \t 4.5561683e-05 \t [1.0078397] \t [2.9821787]\n",
      "1960 \t 4.1380845e-05 \t [1.0074712] \t [2.9830163]\n",
      "1980 \t 3.7581547e-05 \t [1.0071201] \t [2.9838145]\n",
      "2000 \t 3.413363e-05 \t [1.0067855] \t [2.984575]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#데이터 셋\n",
    "x_train=[1,2,3]\n",
    "y_train=[4,5,6]\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "#(H(x))\n",
    "hypothesis=x_train*W+b\n",
    "#손실함수\n",
    "cost=tf.reduce_mean(tf.square(hypothesis-y_train))\n",
    "#경사하강\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#개선\n",
    "train=optimizer.minimize(cost)\n",
    "#훈련\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if (step % 20 == 0):\n",
    "        print(step, '\\t', sess.run(cost), '\\t', sess.run(W), '\\t', sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ZpUHdJpbHkzC",
   "metadata": {
    "id": "ZpUHdJpbHkzC",
    "outputId": "0c320509-8bd7-4c64-9037-aa1d12089a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 99.783165 [-1.5646023] [-0.5082631]\n",
      "20 1.4201412 [1.5082887] [0.9553625]\n",
      "40 0.48100233 [1.7655232] [1.1751189]\n",
      "60 0.429521 [1.7563148] [1.2726569]\n",
      "80 0.39003155 [1.7233198] [1.3549567]\n",
      "100 0.35423222 [1.689569] [1.4323745]\n",
      "120 0.32171935 [1.6571848] [1.5060574]\n",
      "140 0.29219082 [1.6263018] [1.576268]\n",
      "160 0.26537216 [1.5968682] [1.6431783]\n",
      "180 0.24101532 [1.5688175] [1.7069439]\n",
      "200 0.21889405 [1.5420852] [1.7677128]\n",
      "220 0.1988029 [1.5166091] [1.825626]\n",
      "240 0.18055601 [1.4923304] [1.8808172]\n",
      "260 0.16398396 [1.469193] [1.9334146]\n",
      "280 0.14893274 [1.4471425] [1.98354]\n",
      "300 0.13526316 [1.4261285] [2.0313098]\n",
      "320 0.122848146 [1.4061018] [2.0768352]\n",
      "340 0.11157262 [1.3870165] [2.1202207]\n",
      "360 0.10133187 [1.3688279] [2.1615674]\n",
      "380 0.09203116 [1.3514942] [2.2009711]\n",
      "400 0.08358409 [1.3349752] [2.2385225]\n",
      "420 0.07591249 [1.3192327] [2.274309]\n",
      "440 0.06894489 [1.30423] [2.3084142]\n",
      "460 0.06261689 [1.2899321] [2.3409162]\n",
      "480 0.056869607 [1.2763064] [2.3718905]\n",
      "500 0.051649958 [1.2633212] [2.4014094]\n",
      "520 0.046909284 [1.250946] [2.4295409]\n",
      "540 0.042603746 [1.2391526] [2.4563506]\n",
      "560 0.03869347 [1.2279133] [2.4818995]\n",
      "580 0.035142086 [1.2172023] [2.506248]\n",
      "600 0.03191668 [1.2069947] [2.5294523]\n",
      "620 0.028987302 [1.1972668] [2.5515656]\n",
      "640 0.026326666 [1.1879961] [2.5726407]\n",
      "660 0.023910327 [1.179161] [2.5927246]\n",
      "680 0.021715807 [1.1707412] [2.611865]\n",
      "700 0.019722614 [1.1627171] [2.6301064]\n",
      "720 0.01791236 [1.1550697] [2.6474903]\n",
      "740 0.016268253 [1.147782] [2.664057]\n",
      "760 0.014775064 [1.1408365] [2.6798456]\n",
      "780 0.013418918 [1.1342176] [2.694892]\n",
      "800 0.012187294 [1.1279098] [2.709231]\n",
      "820 0.0110686645 [1.1218984] [2.7228963]\n",
      "840 0.010052738 [1.1161696] [2.7359192]\n",
      "860 0.009130031 [1.1107101] [2.74833]\n",
      "880 0.008292082 [1.1055073] [2.760157]\n",
      "900 0.007530999 [1.100549] [2.7714286]\n",
      "920 0.0068397685 [1.0958234] [2.782171]\n",
      "940 0.0062119863 [1.0913202] [2.792408]\n",
      "960 0.005641846 [1.0870285] [2.8021638]\n",
      "980 0.0051240264 [1.0829384] [2.8114614]\n",
      "1000 0.0046537244 [1.0790405] [2.8203218]\n",
      "1020 0.004226576 [1.075326] [2.828766]\n",
      "1040 0.0038386553 [1.071786] [2.836813]\n",
      "1060 0.0034863346 [1.0684124] [2.8444824]\n",
      "1080 0.0031663508 [1.0651973] [2.8517911]\n",
      "1100 0.0028757376 [1.0621336] [2.858756]\n",
      "1120 0.0026117892 [1.0592134] [2.8653939]\n",
      "1140 0.0023720667 [1.0564306] [2.87172]\n",
      "1160 0.0021543165 [1.0537784] [2.8777497]\n",
      "1180 0.0019565844 [1.0512506] [2.8834953]\n",
      "1200 0.001776975 [1.048842] [2.8889709]\n",
      "1220 0.0016138935 [1.0465467] [2.8941884]\n",
      "1240 0.0014657575 [1.0443591] [2.8991616]\n",
      "1260 0.0013312254 [1.0422742] [2.9039006]\n",
      "1280 0.0012090347 [1.0402877] [2.908417]\n",
      "1300 0.0010980625 [1.0383941] [2.912721]\n",
      "1320 0.000997282 [1.0365899] [2.916823]\n",
      "1340 0.0009057209 [1.0348698] [2.920733]\n",
      "1360 0.0008225953 [1.0332311] [2.924458]\n",
      "1380 0.00074709376 [1.0316694] [2.9280083]\n",
      "1400 0.0006785195 [1.0301809] [2.9313915]\n",
      "1420 0.00061624387 [1.0287626] [2.9346159]\n",
      "1440 0.00055968296 [1.0274109] [2.9376886]\n",
      "1460 0.0005083139 [1.0261227] [2.9406168]\n",
      "1480 0.00046166265 [1.0248951] [2.9434078]\n",
      "1500 0.00041929274 [1.023725] [2.9460673]\n",
      "1520 0.0003808071 [1.0226102] [2.948602]\n",
      "1540 0.00034586166 [1.0215476] [2.9510171]\n",
      "1560 0.00031411962 [1.0205353] [2.953319]\n",
      "1580 0.000285287 [1.0195701] [2.9555128]\n",
      "1600 0.00025909697 [1.0186502] [2.9576037]\n",
      "1620 0.00023533781 [1.0177741] [2.9595945]\n",
      "1640 0.00021373329 [1.0169389] [2.961494]\n",
      "1660 0.00019411382 [1.0161428] [2.9633036]\n",
      "1680 0.00017630239 [1.0153842] [2.9650278]\n",
      "1700 0.00016011756 [1.0146612] [2.9666715]\n",
      "1720 0.00014542225 [1.0139724] [2.9682376]\n",
      "1740 0.00013207766 [1.0133159] [2.9697301]\n",
      "1760 0.000119955774 [1.01269] [2.9711528]\n",
      "1780 0.00010894501 [1.0120935] [2.9725087]\n",
      "1800 9.89428e-05 [1.011525] [2.973801]\n",
      "1820 8.985916e-05 [1.0109833] [2.975032]\n",
      "1840 8.161081e-05 [1.0104672] [2.9762056]\n",
      "1860 7.412234e-05 [1.0099752] [2.9773238]\n",
      "1880 6.731906e-05 [1.0095063] [2.9783895]\n",
      "1900 6.114052e-05 [1.0090597] [2.9794052]\n",
      "1920 5.5528173e-05 [1.0086339] [2.9803731]\n",
      "1940 5.042955e-05 [1.0082281] [2.9812956]\n",
      "1960 4.580083e-05 [1.0078413] [2.9821746]\n",
      "1980 4.159795e-05 [1.0074729] [2.9830124]\n",
      "2000 3.7779693e-05 [1.0071217] [2.9838107]\n",
      "[7.0122976]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#데이터 셋\n",
    "x_train=tf.placeholder(tf.float32, shape=[None]) #x_train=[1,2,3]\n",
    "y_train=tf.placeholder(tf.float32, shape=[None]) #y_train=[1,2,3]\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "#(H(x))\n",
    "hypothesis=x_train*W+b\n",
    "#손실함수\n",
    "cost=tf.reduce_mean(tf.square(hypothesis-y_train))\n",
    "#경사하강\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#개선\n",
    "train=optimizer.minimize(cost)\n",
    "#훈련\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    #sess.run(train)\n",
    "    _cost, _W, _b, _= \\\n",
    "      sess.run([cost, W, b, train],\n",
    "               feed_dict={\n",
    "                   x_train: [1,2,3],\n",
    "                   y_train: [4,5,6]\n",
    "               })\n",
    "    if step % 20 == 0:\n",
    "      print(step, _cost, _W, _b)\n",
    "print(sess.run(hypothesis, feed_dict={x_train: [4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5BxaLF64HkzC",
   "metadata": {
    "id": "5BxaLF64HkzC"
   },
   "source": [
    "## XOR 문제 해결을"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "Y7GdpkQTHkzC",
   "metadata": {
    "id": "Y7GdpkQTHkzC",
    "outputId": "8eaa293a-e2bc-42c9-d5c7-44d657209617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('./datasets/train.txt')\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ign2qkN-HkzD",
   "metadata": {
    "id": "ign2qkN-HkzD",
    "outputId": "f63c92bb-2d3a-4d78-bf9c-f4c2d2ba3149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]]\n",
      "*****\n",
      "[1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]\n",
    "\n",
    "print(x_data)\n",
    "print(\"*****\")\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "u8GR165UHkzD",
   "metadata": {
    "id": "u8GR165UHkzD"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "mUOqbzPRHkzD",
   "metadata": {
    "id": "mUOqbzPRHkzD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "\n",
    "# Cross entropy cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "learning_rate = tf.Variable(0.01)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1LBKYggNHkzD",
   "metadata": {
    "id": "1LBKYggNHkzD",
    "outputId": "8f8ebe4f-472a-4fe2-9576-1b1d60c6704c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7252005 [[ 0.71703076  0.7086452  -0.23521915]]\n",
      "500 0.7024825 [[ 0.71703076  0.3825419  -0.24412015]]\n",
      "1000 0.696812 [[ 0.71703076  0.22698489 -0.1870924 ]]\n",
      "1500 0.69470924 [[ 0.71703076  0.14232782 -0.13088115]]\n",
      "2000 0.6938238 [[ 0.71703076  0.09171871 -0.08843996]]\n",
      "2500 0.6934411 [[ 0.71703076  0.05985419 -0.05891579]]\n",
      "3000 0.6932748 [[ 0.71703076  0.03927973 -0.03901122]]\n",
      "3500 0.6932027 [[ 0.71703076  0.02584113 -0.02576433]]\n",
      "4000 0.69317126 [[ 0.71703076  0.01701849 -0.01699655]]\n",
      "4500 0.6931577 [[ 0.71703076  0.0112133  -0.01120706]]\n",
      "5000 0.69315165 [[ 0.71703076  0.00738981 -0.00738807]]\n",
      "[array([[0.49815303, 0.50184745, 0.5000004 ]], dtype=float32), array([[0., 1., 1.]], dtype=float32), array([[False,  True, False]]), 0.33333334]\n",
      "Accuracy: 0.33333334\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(5001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data })\n",
    "        if step % 500 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "\n",
    "# Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "\n",
    "# Calculate Accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sQFWQCQSHkzD",
   "metadata": {
    "id": "sQFWQCQSHkzD"
   },
   "source": [
    "# 신경망 구현: MLP: Neural Network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "VWsuBzTmHkzE",
   "metadata": {
    "id": "VWsuBzTmHkzE",
    "outputId": "63a74615-ced2-4d0f-c6f2-7ef275cd89b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6944671\n",
      "500 0.68914855\n",
      "1000 0.6775025\n",
      "1500 0.6406398\n",
      "2000 0.5671855\n",
      "2500 0.49148384\n",
      "3000 0.4401438\n",
      "3500 0.41030782\n",
      "4000 0.3929873\n",
      "4500 0.38231283\n",
      "5000 0.3752889\n",
      "5500 0.37039945\n",
      "6000 0.3668368\n",
      "6500 0.36414373\n",
      "7000 0.36204618\n",
      "[array([[0.01493686],\n",
      "       [0.9786948 ],\n",
      "       [0.4969698 ],\n",
      "       [0.5095214 ]], dtype=float32)]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "xy = np.loadtxt('./datasets/train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1],(4,1))\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "# define 2 layer Neural Network\n",
    "W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1)+b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2)+b2)\n",
    "# Cross entropy cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "# For this time, learning rate is very important.\n",
    "learning_rate = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(7001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 500 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "    # Test model\n",
    "    correct = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    # Calculate Accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "    print(sess.run([hypothesis],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WVYV81n0HkzE",
   "metadata": {
    "id": "WVYV81n0HkzE"
   },
   "source": [
    "# 신경망 구현: MLP: Wide Neural Network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "zX8URWWVHkzE",
   "metadata": {
    "id": "zX8URWWVHkzE",
    "outputId": "51fcd4ac-f74d-4b20-b78b-fce4a9f59a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7452563\n",
      "2000 0.52043855\n",
      "4000 0.0638545\n",
      "6000 0.022211395\n",
      "8000 0.012534449\n",
      "10000 0.0085215345\n",
      "12000 0.0063795215\n",
      "14000 0.0050636344\n",
      "16000 0.0041796113\n",
      "18000 0.0035477756\n",
      "20000 0.0030752304\n",
      "22000 0.002709373\n",
      "24000 0.002418228\n",
      "26000 0.0021814043\n",
      "28000 0.0019852077\n",
      "30000 0.0018200991\n",
      "[array([[7.4531906e-04],\n",
      "       [9.9822938e-01],\n",
      "       [9.9802375e-01],\n",
      "       [2.7805574e-03]], dtype=float32)]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "xy = np.loadtxt('./datasets/train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1],(4,1))\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "# define 2 layer Neural Network - we will use 10 units\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([10, 1], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1)+b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2)+b2)\n",
    "# Cross entropy cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "# For this time, learning rate is very important.\n",
    "learning_rate = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(30001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "    # Test model\n",
    "    correct = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    # Calculate Accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "    print(sess.run([hypothesis],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FaBV3mPNHkzE",
   "metadata": {
    "id": "FaBV3mPNHkzE"
   },
   "source": [
    "# 신경망 구현: MLP: Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "MMCvtGmtHkzE",
   "metadata": {
    "id": "MMCvtGmtHkzE",
    "outputId": "a53e9a8c-885f-4d74-8c9f-68a8b2df45f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7095448\n",
      "2000 0.60121936\n",
      "4000 0.040793866\n",
      "6000 0.0086068995\n",
      "8000 0.0043414305\n",
      "10000 0.0028203991\n",
      "12000 0.0020622173\n",
      "14000 0.001614095\n",
      "16000 0.001320327\n",
      "18000 0.0011138516\n",
      "20000 0.0009613152\n",
      "22000 0.0008442559\n",
      "24000 0.0007517586\n",
      "26000 0.0006769562\n",
      "28000 0.0006152518\n",
      "30000 0.00056351157\n",
      "[array([[2.7359382e-04],\n",
      "       [9.9937958e-01],\n",
      "       [9.9934131e-01],\n",
      "       [7.0066575e-04]], dtype=float32)]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "xy = np.loadtxt('./datasets/train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1],(4,1))\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "# define 2 layer Neural Network - we will use 3 layers.\n",
    "W1 = tf.Variable(tf.random_uniform([2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([10,5], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform([5,1], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([5]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "L3 = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L3, W3) + b3)\n",
    "# Cross entropy cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "# For this time, learning rate is very important.\n",
    "learning_rate = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(30001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step,\n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data})\n",
    "                #sess.run(W1),\n",
    "                #sess.run(W2)\n",
    "            )\n",
    "    # Test model\n",
    "    correct = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "    print(sess.run([hypothesis],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "OAWsvW7lHkzF",
   "metadata": {
    "id": "OAWsvW7lHkzF"
   },
   "outputs": [],
   "source": [
    "# 신경망 구현: MLP: Deep Neural Network 좀 더 깊이를 더하면…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6TJNW0uYHkzF",
   "metadata": {
    "id": "6TJNW0uYHkzF",
    "outputId": "ac0c628f-a059-47af-a0d3-e89c9c3c1f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7009176\n",
      "2000 0.6793457\n",
      "4000 0.0026507694\n",
      "6000 0.0009860427\n",
      "8000 0.00058764446\n",
      "10000 0.00041332858\n",
      "12000 0.00031661283\n",
      "14000 0.00025546993\n",
      "16000 0.00021349794\n",
      "18000 0.00018300382\n",
      "20000 0.00015985817\n",
      "22000 0.00014173548\n",
      "24000 0.00012716008\n",
      "26000 0.00011523765\n",
      "28000 0.00010528252\n",
      "30000 9.6862466e-05\n",
      "[array([[6.20432766e-05],\n",
      "       [9.99892473e-01],\n",
      "       [9.99902010e-01],\n",
      "       [1.19836724e-04]], dtype=float32)]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "xy = np.loadtxt('./datasets/train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1],(4,1))\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "# define 2 layer Neural Network - we will use 3 layers.\n",
    "W1 = tf.Variable(tf.random_uniform([2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([10,10], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform([10,10], -1.0, 1.0))\n",
    "W4 = tf.Variable(tf.random_uniform([10,1], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([10]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([10]), name=\"Bias3\")\n",
    "b4 = tf.Variable(tf.zeros([1]), name=\"Bias4\")\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "L3 = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "L4 = tf.sigmoid(tf.matmul(L3, W3) + b2)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L4, W4) + b4)\n",
    "# Cross entropy cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "# For this time, learning rate is very important.\n",
    "learning_rate = tf.Variable(0.3)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(30001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step,\n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data})\n",
    "                #sess.run(W1),\n",
    "                #sess.run(W2)\n",
    "            )\n",
    "    # Test model\n",
    "    correct = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "    print(sess.run([hypothesis],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x7ttSidcHkzF",
   "metadata": {
    "id": "x7ttSidcHkzF"
   },
   "source": [
    "# 텐서플로와 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fe4c1-86f8-4088-a77a-74590e1054fe",
   "metadata": {},
   "source": [
    "학습 시간이 많이 걸립니다. 시간이 많을 때 실행 해 보세요 ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CfbNjNicHkzF",
   "metadata": {
    "id": "CfbNjNicHkzF",
    "outputId": "cc7a32bb-681d-408b-a6d7-c2119bbc7638",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Train on 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2756\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2752\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2748\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.2756\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 11ms/sample - loss: 0.2730\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2737\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2727\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2730\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2728\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2727\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2725\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/sample - loss: 0.2726\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2724\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 11ms/sample - loss: 0.2722\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2707\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2720\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2718\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2709\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/sample - loss: 0.2715\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2704\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2713\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2713\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2711\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2710\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2699\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2698\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2699\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 42ms/sample - loss: 0.2708\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2707\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 16ms/sample - loss: 0.2693\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2695\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2701\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2690\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2685\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2698\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2697\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2683\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2695\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2682\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2681\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2685\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2685\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2680\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2692\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2691\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 0s/sample - loss: 0.2688\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 0.2688\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2677\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2687\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2685\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2686\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2685\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2673\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2684\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2683\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2683\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2671\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2683\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2681\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2667\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2680\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2672\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2679\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.2678\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2677\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2678\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2678\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2676\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2675\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2676\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2675\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2675\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2673\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2666\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2664\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2661\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2674\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2662\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2673\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2673\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2672\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2672\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2671\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2659\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2670\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2669\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2657\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2659\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2660\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2667\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2668\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2667\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2667\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2655\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2666\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2655\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2666\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2664\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2664\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2652\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2663\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2662\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2663\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2662\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2663\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2652\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2661\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2650\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2661\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2662\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2660\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2660\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2659\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2659\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2650\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2659\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2658\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2649\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2649\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 0s 39ms/sample - loss: 0.2657\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2657\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.2656\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2646\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2649\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2656\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2646\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2654\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2654\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2653\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2644\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2654\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 0s 14ms/sample - loss: 0.2654\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2652\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2653\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2652\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2652\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2652\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2651\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2651\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2642\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2652\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2651\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2650\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2650\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2650\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2641\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2649\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2649\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2650\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2649\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2649\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2640\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2638\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2648\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2639\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2639\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2637\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2646\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2639\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2647\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2646\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2645\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2644\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2644\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2644\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2635\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2642\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2643\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2642\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2634\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2640\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2632\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2640\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2640\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2635\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2634\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2640\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2639\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2639\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2640\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2641\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2640\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2639\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2639\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2631\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2638\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2630\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2630\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2636\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2628\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2636\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2636\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 0s 13ms/sample - loss: 0.2629\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2635\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2626\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2635\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2634\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2626\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.2627\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2627\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2634\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2634\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2634\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2627\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2634\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2626\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2634\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.2634\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2625\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2633\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2626\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2625\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2632\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2632\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2632\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 0.2631\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2625\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2631\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2631\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.2631\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2631\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 0s 11ms/sample - loss: 0.2623\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2631\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2630\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2630\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2630\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2629\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2628\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2628\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2628\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2628\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2627\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2620\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2619\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2619\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2626\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2620\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2620\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2627\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2626\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2625\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2625\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2625\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2624\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2625\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2616\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2623\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2623\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2616\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2624\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2623\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2623\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2623\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2615\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2622\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2614\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2620\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2620\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2621\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2614\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2613\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2614\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2619\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2620\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2612\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2619\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2613\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2619\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2611\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2618\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2611\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2611\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2612\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2618\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2617\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2616\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2616\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2616\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2616\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2615\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2615\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2614\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2606\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2613\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2606\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2606\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2613\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2607\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2613\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2612\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2611\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2611\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2611\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2610\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2604\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2611\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2610\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2609\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2603\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2608\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 0.2601\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2608\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2599\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2601\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2607\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2607\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2599\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2606\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2600\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2600\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 0.2598\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2605\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2604\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2598\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2604\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2597\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2595\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2602\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 0s 34ms/sample - loss: 0.2596\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2602\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2594\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2601\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2600\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2600\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2593\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2593\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2600\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 0s 9ms/sample - loss: 0.2598\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2598\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2592\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2598\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2597\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2591\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2591\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2595\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2595\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2595\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2589\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2594\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2594\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2587\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2593\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2591\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2586\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2583\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2591\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2590\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 0s 993us/sample - loss: 0.2589\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2589\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2588\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 0s 989us/sample - loss: 0.2583\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2588\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2587\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2586\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2585\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2585\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2585\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2576\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2583\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 0s 988us/sample - loss: 0.2583\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2582\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 0s 989us/sample - loss: 0.2581\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 0s 983us/sample - loss: 0.2575\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2580\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.2579\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2572\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2579\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2573\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2578\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2571\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2575\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2575\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2567\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2574\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 0s 13ms/sample - loss: 0.2573\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2572\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2571\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2564\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2565\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2568\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2562\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2567\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 0s 988us/sample - loss: 0.2561\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2566\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2564\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2563\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2563\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2562\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2556\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2554\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2559\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2558\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2557\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 0s 13ms/sample - loss: 0.2551\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2554\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2546\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2552\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2546\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2550\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2550\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2548\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2547\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2545\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2545\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2544\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2543\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2541\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2541\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2538\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2538\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2536\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2535\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.2534\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2525\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2532\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2530\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2528\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2527\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2526\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2525\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2522\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2514\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2520\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2519\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2517\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2516\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2514\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2508\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2510\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2509\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2508\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2498\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2498\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2494\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2493\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2499\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2492\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2490\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2494\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2491\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2490\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2488\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2485\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2483\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2480\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2479\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2473\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2475\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2472\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2471\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2469\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2465\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2464\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2462\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2459\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2457\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2450\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2453\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2442\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2449\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2438\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2444\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2437\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2439\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2436\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2433\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2427\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2428\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2426\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2423\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2420\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2417\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2406\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2412\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.2406\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2406\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2404\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2399\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2398\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2392\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2392\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2383\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2386\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.2382\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2372\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2377\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2367\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2371\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2360\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2363\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2358\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2358\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2355\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2351\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2344\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2345\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2343\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2339\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2335\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2331\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 0s 15ms/sample - loss: 0.2329\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2322\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2322\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2312\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2308\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2312\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2309\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2306\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2302\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 0s 10ms/sample - loss: 0.2299\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2294\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2291\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2289\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2284\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2281\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2276\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2275\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2271\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2267\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2264\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2261\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2249\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2251\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2248\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2245\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2241\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2239\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2236\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2232\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2223\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2224\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2220\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2217\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2213\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2208\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2207\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2202\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2198\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2195\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2190\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2187\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2178\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2181\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2178\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2175\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2170\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2168\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2157\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2160\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2155\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2152\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2147\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2146\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2143\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2139\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2135\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2129\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2127\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2122\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2118\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2115\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2106\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2110\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2106\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2101\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2099\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2089\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2090\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2088\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2083\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2075\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2078\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2069\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2070\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2067\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2063\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2054\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2056\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2051\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2049\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2045\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2042\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2032\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2033\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2031\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2028\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2022\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2014\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2011\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2009\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2003\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2006\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2003\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1997\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1995\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1988\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1988\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1984\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1981\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1975\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1970\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1966\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1965\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1957\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1959\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1953\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1950\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1946\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1941\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1940\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1936\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1926\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1923\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1922\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1921\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1911\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1913\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1906\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1903\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1901\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1895\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1891\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1888\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1883\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1880\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1870\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1866\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1867\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1863\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1859\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1852\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1849\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1843\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1840\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1834\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 0s 66ms/sample - loss: 0.1826\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1825\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1822\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1818\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1813\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1804\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1804\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1799\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1794\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 0s 38ms/sample - loss: 0.1787\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1782\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1779\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1774\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1766\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1761\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1757\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1753\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 0.1746\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1742\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 0.1734\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 0s 999us/sample - loss: 0.1730\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1723\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1717\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1711\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1707\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1696\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1695\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1689\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.1681\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1676\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1670\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1662\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1656\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1645\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1643\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1635\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1629\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1619\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1612\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1609\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1596\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1591\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1587\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1578\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1571\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1566\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1555\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1549\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1542\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1533\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1521\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1518\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1510\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1496\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1493\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1483\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1470\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1464\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1459\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1450\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1440\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1431\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1421\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1412\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1404\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1394\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1384\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1375\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1366\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1355\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1344\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1337\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1326\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1312\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1308\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1296\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1286\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1276\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1265\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1255\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1241\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1235\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1221\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1214\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1203\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1195\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1181\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1173\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1159\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1149\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1141\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1128\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1118\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1106\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1096\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1088\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1076\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1067\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1057\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1043\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1036\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1022\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1015\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1003\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0990\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0983\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0973\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0961\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0951\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0943\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0930\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0923\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0913\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0901\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0892\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0883\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0873\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0862\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0854\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0845\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0836\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0826\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0818\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0808\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0798\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0789\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0782\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0772\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0763\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0756\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0747\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0739\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0730\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0721\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0715\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0707\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0698\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0690\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0683\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0674\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0668\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0659\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0653\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0645\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0638\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0630\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0623\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0616\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0610\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0604\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0597\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0590\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0584\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0578\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0572\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0565\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0559\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0552\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0547\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0541\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0535\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0530\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0524\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0518\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0513\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0508\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0502\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0497\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0491\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0487\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0481\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0477\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 0s 30ms/sample - loss: 0.0472\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0468\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0462\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 0s 981us/sample - loss: 0.0458\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0453\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0449\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0445\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0440\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 0s 986us/sample - loss: 0.0435\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0431\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0427\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0423\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0419\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0414\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0411\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0407\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0403\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0399\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 0s 990us/sample - loss: 0.0396\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 0s 46ms/sample - loss: 0.0392\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0388\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0385\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0381\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0378\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0374\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0370\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0367\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 0s 865us/sample - loss: 0.0364\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0361\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0358\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0354\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0351\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0348\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0345\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0342\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0339\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0336\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 0.0333\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0330\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0328\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0325\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0322\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0319\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0317\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0314\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0312\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0309\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0307\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0304\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0302\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0299\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0297\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0295\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0292\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0290\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0288\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0285\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0283\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0281\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0279\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0277\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0275\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0272\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0270\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0268\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0266\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0264\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0262\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0261\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0259\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0257\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0255\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0253\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0251\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0249\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0248\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0246\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0244\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0242\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0241\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0239\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0237\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0236\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0234\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0233\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0231\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0230\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0228\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0226\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0225\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0223\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0222\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0220\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0219\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0218\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0216\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0215\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0213\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0212\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0211\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0209\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0208\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0207\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0204\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0203\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0202\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0200\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0199\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0198\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0197\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0194\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0193\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0192\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0191\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0190\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0189\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0187\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0184\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0182\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0181\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0177\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0175\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0171\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0165\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0162\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0160\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0159\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0158\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0150\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0149\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0148\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0148\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0146\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0145\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0141\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0140\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0137\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0136\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0133\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0131\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0128\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 0.0125\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 0.0124\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0122\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0122\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0121\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 0.0120\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0119\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0113\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0109\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0103\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0101\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0100\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0099\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0098\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0097\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0097\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0096\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0094\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0093\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0090\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0090\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0088\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0087\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0085\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0085\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0081\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0081\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0079\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0078\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0077\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0077\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0076\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 0s 37ms/sample - loss: 0.0075\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0075\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0074\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0073\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 0.0070\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0070\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0070\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0068\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0068\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0068\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0067\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0067\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0066\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0066\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0065\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0064\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0063\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0061\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0060\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0059\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0059\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0058\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0057\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0057\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0057\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0056\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0056\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0056\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0055\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0055\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0053\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0052\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 0.0051\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0051\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0050\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0050\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0049\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0049\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 0.0049\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0048\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0048\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0048\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0048\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.0048\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0047\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0046\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0046\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0046\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0045\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0045\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0045\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0045\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0044\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0044\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0044\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0043\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0043\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0043\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0042\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0042\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0042\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0042\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0041\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0041\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0040\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0040\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0040\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0040\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0039\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0038\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0038\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0038\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0038\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0038\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0038\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.0037\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0037\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0037\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 0.0037\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 0s 11ms/sample - loss: 0.0036\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0036\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0036\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0036\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0035\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0035\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0035\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0035\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0034\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0034\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0033\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.0033\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0032\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0032\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0031\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0030\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0030\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0030\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 0s 31ms/sample - loss: 0.0030\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0030\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 0.0030\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0030\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0030\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0030\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0029\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1832/2000\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 0.0029\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 0.0029\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0029\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0029\n",
      "Epoch 1841/2000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0024"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 3.27 tf.keras 를 이용한 XOR 네트워크 계산\n",
    "import numpy as np\n",
    "x = np.array([[1,1], [1,0], [0,1], [0,0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=2, activation='sigmoid', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.3), loss='mse')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 3.28 tf.keras 를 이용한 XOR 네트워크 학습\n",
    "history = model.fit(x, y, epochs=2000, batch_size=1)\n",
    "\n",
    "# 3.29 tf.keras 를 이용한 XOR 네트워크 평가\n",
    "model.predict(x)\n",
    "\n",
    "# 3.30 XOR 네트워크의 가중치와 편향 확인\n",
    "for weight in model.weights:\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41dbb49e-5fea-475a-af17-42ad73e81c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "021e7abb-5b31-4a7c-a41b-9893c54e3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.3\n",
      "  Using cached numpy-1.24.3-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.3-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\DEV\\miniconda3\\envs\\tf38_cpu\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "Z0s8wTI3HkzF",
   "metadata": {
    "id": "Z0s8wTI3HkzF",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdisable_v2_behavior()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Eager execution must be called at the beginning of the program\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_eager_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5624\u001b[0m, in \u001b[0;36menable_eager_execution\u001b[1;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[0;32m   5622\u001b[0m logging\u001b[38;5;241m.\u001b[39mvlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnabling eager execution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mdefault_execution_mode \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mEAGER_MODE:\n\u001b[1;32m-> 5624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menable_eager_execution_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5626\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5627\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexecution_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5628\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserver_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5688\u001b[0m, in \u001b[0;36menable_eager_execution_internal\u001b[1;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[0;32m   5685\u001b[0m   graph_mode_has_been_used \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   5686\u001b[0m       _default_graph_stack\u001b[38;5;241m.\u001b[39m_global_default_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5687\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m graph_mode_has_been_used:\n\u001b[1;32m-> 5688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   5689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.enable_eager_execution must be called at program startup.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5690\u001b[0m context\u001b[38;5;241m.\u001b[39mdefault_execution_mode \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mEAGER_MODE\n\u001b[0;32m   5691\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "# Eager execution must be called at the beginning of the program\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "# OR 데이터 구축\n",
    "x = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "y = np.array([[-1], [1], [1], [1]])\n",
    "\n",
    "# Define the model\n",
    "perceptron = Sequential([\n",
    "    Dense(units=1, activation='tanh', input_shape=(2,))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "perceptron.compile(loss='mse', optimizer=SGD(learning_rate=0.1), metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "perceptron.fit(x, y, epochs=500, verbose=2)\n",
    "\n",
    "# Predict using the trained model\n",
    "res = perceptron.predict(x)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uWV_bqyeHkzF",
   "metadata": {
    "id": "uWV_bqyeHkzF"
   },
   "source": [
    "# LeNet-5 사례 [LeCun1998] 재현해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "J50nGPjtHkzG",
   "metadata": {
    "id": "J50nGPjtHkzG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "numpy() is only available when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m cnn\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 신경망 모델 학습\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m hist\u001b[38;5;241m=\u001b[39mcnn\u001b[38;5;241m.\u001b[39mfit(x_train,y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(x_test,y_test),verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 신경망 모델 정확률 평가\u001b[39;00m\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:321\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_eagerly:\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    316\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession keyword arguments are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen `run_eagerly=True`. You passed the following \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession arguments: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_kwargs,)\n\u001b[0;32m    319\u001b[0m         )\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m is_any_keras_optimizer_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    323\u001b[0m     (\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(opt, optimizer_v1\u001b[38;5;241m.\u001b[39mOptimizer)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m opt \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n\u001b[0;32m    328\u001b[0m )\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    331\u001b[0m     is_any_keras_optimizer_v1\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions()\n\u001b[0;32m    333\u001b[0m ):\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:1473\u001b[0m, in \u001b[0;36mModel._set_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m   1471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m [optimizers\u001b[38;5;241m.\u001b[39mget(opt) \u001b[38;5;28;01mfor\u001b[39;00m opt \u001b[38;5;129;01min\u001b[39;00m optimizer]\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype_policy\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed_float16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, loss_scale_optimizer\u001b[38;5;241m.\u001b[39mLossScaleOptimizer\n\u001b[0;32m   1477\u001b[0m ):\n\u001b[0;32m   1478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:298\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m         optimizer_name \u001b[38;5;241m=\u001b[39m identifier\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    292\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is a known slowdown when using v2.11+ Keras optimizers \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon M1/M2 Macs. Falling back to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy Keras optimizer, i.e., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m         )\n\u001b[1;32m--> 298\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_legacy_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Wrap legacy TF optimizer instances\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(identifier, tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mOptimizer):\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:222\u001b[0m, in \u001b[0;36mconvert_to_legacy_optimizer\u001b[1;34m(optimizer)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`convert_to_legacy_optimizer` should only be called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon instances of `tf.keras.optimizers.Optimizer`, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(optimizer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n\u001b[0;32m    221\u001b[0m optimizer_name \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m--> 222\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Remove fields that only exist in experimental optimizer.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m keys_to_remove \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_ema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_legacy_optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m ]\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\optimizers\\adam.py:211\u001b[0m, in \u001b[0;36mAdam.get_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    207\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_config()\n\u001b[0;32m    209\u001b[0m     config\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    210\u001b[0m         {\n\u001b[1;32m--> 211\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize_hyperparameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learning_rate\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1,\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta_2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2,\n\u001b[0;32m    216\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    217\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad,\n\u001b[0;32m    218\u001b[0m         }\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:736\u001b[0m, in \u001b[0;36m_BaseOptimizer._serialize_hyperparameter\u001b[1;34m(self, hyperparameter)\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learning_rate_schedule\u001b[38;5;241m.\u001b[39mserialize(hyperparameter)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hyperparameter, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhyperparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hyperparameter):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hyperparameter()\n",
      "File \u001b[1;32mC:\\DEV\\miniconda3\\envs\\tf38_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m--> 689\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: numpy() is only available when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# MNIST 데이터셋을 읽고 신경망에 입력할 형태로 변환\n",
    "(x_train,y_train),(x_test,y_test)= mnist.load_data()\n",
    "x_train=x_train.reshape(60000,28,28,1)\n",
    "x_test=x_test.reshape(10000,28,28,1)\n",
    "x_train=x_train.astype(np.float32)/255.0\n",
    "x_test=x_test.astype(np.float32)/255.0\n",
    "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "# LeNet-5 신경망 모델 설계\n",
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(6,(5,5),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16,(5,5),padding='same',activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(120,(5,5),padding='same',activation='relu'))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(84,activation='relu'))\n",
    "cnn.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# 신경망 모델 학습\n",
    "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "hist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
    "\n",
    "# 신경망 모델 정확률 평가\n",
    "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"정확률은\",res[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ISXilCB7HkzG",
   "metadata": {
    "id": "ISXilCB7HkzG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 정확률 그래프\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhist\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확률 그래프\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Validation'],loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 손실 함수 그래프\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Validation'],loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4iSi2Js5HkzG",
   "metadata": {
    "id": "4iSi2Js5HkzG"
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "t_xwvcOQHkzG",
   "metadata": {
    "id": "t_xwvcOQHkzG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k8s\\AppData\\Local\\Temp\\ipykernel_9140\\4088922680.py:31: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True, reuse=tf.compat.v1.AUTO_REUSE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 1.6231875 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "1 loss: 1.472727 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "2 loss: 1.3953539 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "3 loss: 1.3403486 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "4 loss: 1.2473465 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  llllll\n",
      "5 loss: 1.1330713 prediction:  [[2 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ehello\n",
      "6 loss: 1.0304064 prediction:  [[2 0 2 3 4 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  eheloo\n",
      "7 loss: 0.9380675 prediction:  [[0 0 2 3 4 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  hheloo\n",
      "8 loss: 0.8421379 prediction:  [[0 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  hhello\n",
      "9 loss: 0.7365717 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "10 loss: 0.6263275 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "11 loss: 0.52237684 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "12 loss: 0.43051925 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "13 loss: 0.35014057 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "14 loss: 0.28216383 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "15 loss: 0.22598143 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "16 loss: 0.17899962 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "17 loss: 0.13978907 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "18 loss: 0.10820394 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "19 loss: 0.08382416 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "20 loss: 0.06557062 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "21 loss: 0.052120417 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "22 loss: 0.042217653 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "23 loss: 0.03479987 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "24 loss: 0.029065976 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "25 loss: 0.024487207 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "26 loss: 0.020750588 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "27 loss: 0.0176731 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "28 loss: 0.015134662 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "29 loss: 0.013041623 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "30 loss: 0.011313888 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "31 loss: 0.00988285 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "32 loss: 0.008692543 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "33 loss: 0.0076993178 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "34 loss: 0.006869269 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "35 loss: 0.0061752186 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "36 loss: 0.005593747 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "37 loss: 0.0051044035 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "38 loss: 0.004689668 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "39 loss: 0.004335175 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "40 loss: 0.004029972 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "41 loss: 0.0037656606 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "42 loss: 0.003535797 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "43 loss: 0.0033354245 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "44 loss: 0.0031597784 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "45 loss: 0.0030048203 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "46 loss: 0.0028665455 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "47 loss: 0.002741994 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "48 loss: 0.0026290733 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n",
      "49 loss: 0.0025265592 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
      "\tPrediction str:  ihello\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "tf.compat.v1.set_random_seed(777)  # reproducibility\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "# Teach hello: hihell -> ihello\n",
    "x_data = [[0, 1, 0, 2, 3, 3]]   # hihell\n",
    "x_one_hot = np.array([[[1, 0, 0, 0, 0],   # h 0\n",
    "                       [0, 1, 0, 0, 0],   # i 1\n",
    "                       [1, 0, 0, 0, 0],   # h 0\n",
    "                       [0, 0, 1, 0, 0],   # e 2\n",
    "                       [0, 0, 0, 1, 0],   # l 3\n",
    "                       [0, 0, 0, 1, 0]]])  # l 3\n",
    "\n",
    "y_data = [[1, 0, 2, 3, 3, 4]]    # ihello\n",
    "\n",
    "num_classes = 5\n",
    "input_dim = 5  # one-hot size\n",
    "hidden_size = 5  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 6  # |ihello| == 6\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.placeholder(\n",
    "    tf.float32, [None, sequence_length, input_dim])  # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])  # Y label\n",
    "\n",
    "# Define LSTM cell\n",
    "cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True, reuse=tf.compat.v1.AUTO_REUSE)\n",
    "\n",
    "# Initialize cell state\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Run dynamic RNN\n",
    "outputs, _states = tf.compat.v1.nn.dynamic_rnn(\n",
    "    cell, X, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "# FC layer\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "dense = tf.keras.layers.Dense(num_classes, activation=None)\n",
    "outputs = dense(X_for_fc)\n",
    "\n",
    "# Reshape output for sequence_loss\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "    y_true=Y, y_pred=outputs, from_logits=True)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"\\tPrediction str: \", ''.join(result_str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hr8CsTdeHkzG",
   "metadata": {
    "id": "Hr8CsTdeHkzG"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ur3NE0vDHkzH",
   "metadata": {
    "id": "ur3NE0vDHkzH"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_random_seed\u001b[49m(\u001b[38;5;241m777\u001b[39m)  \u001b[38;5;66;03m# reproducibility\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am a boy. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre a girl.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m idx2char \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(sample))  \u001b[38;5;66;03m# index -> char\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "sample = \"I am a boy. You're a girl.\"\n",
    "idx2char = list(set(sample))  # index -> char\n",
    "char2idx = {c: i for i, c in enumerate(idx2char)}  # char -> idex\n",
    "\n",
    "# hyper parameters\n",
    "dic_size = len(char2idx)  # RNN input size (one hot size)\n",
    "hidden_size = len(char2idx)  # RNN output size\n",
    "num_classes = len(char2idx)  # final output size (RNN or softmax, etc.)\n",
    "batch_size = 1  # one sample data, one batch\n",
    "sequence_length = len(sample) - 1  # number of lstm rollings (unit #)\n",
    "learning_rate = 0.1\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample]  # char to index\n",
    "x_data = [sample_idx[:-1]]  # X data sample (0 ~ n-1) hello: hell\n",
    "y_data = [sample_idx[1:]]   # Y label sample (1 ~ n) hello: ello\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])  # X data\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])  # Y label\n",
    "\n",
    "x_one_hot = tf.one_hot(X, num_classes)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, x_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "# FC layer\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=None)\n",
    "\n",
    "# reshape out for sequence_loss\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_data, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_data})\n",
    "\n",
    "        # print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "\n",
    "        print(i, \"loss:\", l, \"Prediction:\", ''.join(result_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrjLP4xdHkzH",
   "metadata": {
    "id": "wrjLP4xdHkzH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b2963-f963-435a-a217-af92b7b80f1a",
   "metadata": {
    "id": "1a6b2963-f963-435a-a217-af92b7b80f1a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf38_cpu",
   "language": "python",
   "name": "tf38_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
